@article{GSU2022,
title = {Functional estimation of extreme conditional expectiles},
journal = {Econometrics and Statistics},
volume = {21},
pages = {131-158},
year = {2022},
issn = {2452-3062},
doi = {https://doi.org/10.1016/j.ecosta.2021.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S2452306221000642},
author = {Stéphane Girard and Gilles Stupfler and Antoine Usseglio-Carleve},
keywords = {Conditional tail index, Expectiles, Extrapolation, Extremes, Functional kernel estimator, Heavy tails, Nonparametric estimation}
}

@article{Stupfler2019_Random_threshold,
author = {Stupfler, Gilles},
year = {2019},
pages = {749-769},
title = {On a relationship between randomly and non-randomly thresholded empirical average excesses for heavy tails},
volume = {22},
journal = {Extremes},
doi = {10.1007/s10687-019-00351-5}
}

@article{ChangPollard97,
author = {Chang, J. T. and Pollard, D.},
title = {Conditioning as disintegration},
journal = {Statistica Neerlandica},
volume = {51},
number = {3},
pages = {287-317},
keywords = {Conditional probability distributions, disintegrations, EM algorithm, sufficiency, Bayes theory, admissibility, marginalization paradoxes, Basu's theorem, exchangeability},
doi = {https://doi.org/10.1111/1467-9574.00056},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/1467-9574.00056},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/1467-9574.00056},
abstract = {Conditional probability distributions seem to have a bad reputation when it comes to rigorous treatment of conditioning. Technical arguments are published as manipulations of Radon–Nikodym derivatives, although we all secretly perform heuristic calculations using elementary definitions of conditional probabilities. In print, measurability and averaging properties substitute for intuitive ideas about random variables behaving like constants given particular conditioning information. One way to engage in rigorous, guilt-free manipulation of conditional distributions is to treat them as disintegrating measures—families of probability measures concentrating on the level sets of a conditioning statistic. In this paper we present a little theory and a range of examples—from EM algorithms and the Neyman factorization, through Bayes theory and marginalization paradoxes—to suggest that disintegrations have both intuitive appeal and the rigor needed for many problems in mathematical statistics.},
year = {1997}
}

@article{all_stars2015,
 ISSN = {13697412, 14679868},
 URL = {http://www.jstor.org/stable/24774743},
 author = {Juan-Juan Cai and John H. J. Einmahl and Laurens de Haan and Chen Zhou},
 journal = {Journal of the Royal Statistical Society. Series~B (Statistical Methodology)},
 number = {2},
 pages = {417--442},
 publisher = {[Royal Statistical Society, Wiley]},
 title = {Estimation of the marginal expected shortfall: the mean when a related variable is extreme},
 urldate = {2024-06-08},
 volume = {77},
 year = {2015}
}

@article{Gardes2020,
author = {Laurent Gardes},
title = {{Nonparametric confidence intervals for conditional quantiles with large-dimensional covariates}},
volume = {14},
journal = {Electronic Journal of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {661--701},
keywords = {Confidence interval, Dimension reduction, Extreme conditional quantiles},
year = {2020},
doi = {10.1214/20-EJS1678},
URL = {https://doi.org/10.1214/20-EJS1678}
}

@article{Aghbalou2024,
author = {Anass Aghbalou and Fran{\c{c}}ois Portier and Anne Sabourin and Chen Zhou},
title = {{Tail inverse regression: Dimension reduction for prediction of extremes}},
volume = {30},
journal = {Bernoulli},
number = {1},
publisher = {Bernoulli Society for Mathematical Statistics and Probability},
pages = {503--533},
keywords = {Dimension reduction, Empirical processes, extreme events, inverse regression, supervised learning},
year = {2024},
doi = {10.3150/23-BEJ1606},
URL = {https://doi.org/10.3150/23-BEJ1606}
}

@article{GG2012,
author = {Laurent Gardes and St\'{e}phane Girard},
title = {{Functional kernel estimators of large conditional quantiles}},
volume = {6},
journal = {Electronic Journal of Statistics},
publisher = {Institute of Mathematical Statistics and Bernoulli Society},
pages = {1715--1744},
keywords = {conditional quantiles, extreme-value theory, functional kernel estimator, heavy-tailed distributions},
year = {2012},
doi = {10.1214/12-EJS727},
URL = {https://doi.org/10.1214/12-EJS727}
}
@article{FukumizuBachJordan2009AoS,
author = {Kenji Fukumizu and Francis R. Bach and Michael I. Jordan},
title = {{Kernel dimension reduction in regression}},
volume = {37},
journal = {The Annals of Statistics},
number = {4},
publisher = {Institute of Mathematical Statistics},
pages = {1871--1905},
keywords = {consistency, Dimension reduction, Positive definite kernel, regression, reproducing kernel},
year = {2009},
doi = {10.1214/08-AOS637},
URL = {https://doi.org/10.1214/08-AOS637}
}

@book{FerratyVieu2006,
author = {Ferraty, Fr\'{e}d\'{e}ric and Vieu, Philippe},
title = {Nonparametric Functional Data Analysis: Theory and Practice (Springer Series in Statistics)},
year = {2006},
isbn = {0387303693},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg}
}
@book{bosq2000linear,
  title={Linear Processes in Function Spaces: Theory and Applications},
  author={Bosq, D.},
  isbn={9780387950525},
  lccn={00040041},
  series={Lecture Notes in Statistics},
  url={https://books.google.fr/books?id=lqWEH23nytQC},
  year={2000},
  publisher={Springer New York}
}

@article{TanShiYu2020AoS,
author = {Kai Tan and Lei Shi and Zhou Yu},
title = {{Sparse SIR: Optimal rates and adaptive estimation}},
volume = {48},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {64--85},
keywords = {sliced inverse regression, Sparsity, sufficient dimension reduction},
year = {2020},
doi = {10.1214/18-AOS1791},
URL = {https://doi.org/10.1214/18-AOS1791}
}

@article{LiHsing2010AoS,
author = {Yehua Li and Tailen Hsing},
title = {{Deciding the dimension of effective dimension reduction space for functional and high-dimensional data}},
volume = {38},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {3028--3062},
keywords = {Adaptive Neyman test, Dimension reduction, elliptically contoured distribution, Functional data analysis, principal components},
year = {2010},
doi = {10.1214/10-AOS816},
URL = {https://doi.org/10.1214/10-AOS816}
}

@book{Ramsay2005,
  author = {Ramsay, J. O. and Silverman, B. W.},
  isbn = {9780387400808},
  publisher = {Springer},
  title = {{Functional Data Analysis}},
  year = 2005
}

@article{ReissOgden2007,
author = {Philip T Reiss and R. Todd Ogden},
title = {Functional Principal Component Regression and Functional Partial Least Squares},
journal = {Journal of the American Statistical Association},
volume = {102},
number = {479},
pages = {984-996},
year = {2007},
publisher = {Taylor \& Francis},
doi = {10.1198/016214507000000527},
URL = {https://doi.org/10.1198/016214507000000527},
eprint = {https://doi.org/10.1198/016214507000000527}
}
@article{LianLi2014,
title = {Series expansion for functional sufficient dimension reduction},
journal = {Journal of Multivariate Analysis},
volume = {124},
pages = {150-165},
year = {2014},
issn = {0047-259X},
doi = {https://doi.org/10.1016/j.jmva.2013.10.019},
url = {https://www.sciencedirect.com/science/article/pii/S0047259X13002261},
author = {Heng Lian and Gaorong Li},
keywords = {Functional principal component analysis, Polynomial splines, Sliced average variance estimation, Sliced inverse regression},
abstract = {Functional data are infinite-dimensional statistical objects which pose significant challenges to both theorists and practitioners. Both parametric and nonparametric regressions have received attention in the functional data analysis literature. However, the former imposes stringent constraints while the latter suffers from logarithmic convergence rates. In this article, we consider two popular sufficient dimension reduction methods in the context of functional data analysis, which, if desired, can be combined with low-dimensional nonparametric regression in a later step. In computation, predictor processes and index vectors are approximated in finite dimensional spaces using the series expansion approach. In theory, the basis used can be either fixed or estimated, which include both functional principal components and B-spline basis. Thus our study is more general than previous ones. Numerical results from simulations and a real data analysis are presented to illustrate the methods.}
}
@article{Lian2015,
title = {Functional sufficient dimension reduction: Convergence rates and multiple functional case},
journal = {Journal of Statistical Planning and Inference},
volume = {167},
pages = {58-68},
year = {2015},
issn = {0378-3758},
doi = {https://doi.org/10.1016/j.jspi.2015.05.008},
url = {https://www.sciencedirect.com/science/article/pii/S0378375815001135},
author = {Heng Lian},
keywords = {Convergence rates, Functional data, Regularization, Sliced average variance estimation, Sliced inverse regression},
abstract = {Although sufficient dimension reduction for functional data has received some attention in the literature, its theoretical properties are less understood. Besides, the current literature only focused on sliced inverse regression (SIR). In this paper we consider functional version of SIR and SAVE (sliced average variance estimation) via a Tikhonov regularization approach. Besides consistency, we show that their convergence rates are the same as the minimax rates for functional linear regression, which we think is an interesting theoretical result given that sufficient dimension reduction is much more flexible than functional linear regression. In sufficient dimension reduction, it is well known that estimation of multiple directions requires extraction of multiple eigenfunctions. We also consider multiple functional dimension reduction, in which one eigenfunction surprisingly recovers multiple index functions at once, despite its similarity with single functional case. The numerical properties are illustrated using several simulation examples as well as a Japanese weather dataset.}
}
@article{WangLian2020, 
 title     = "Functional sliced inverse regression in a reproducing kernel {H}ilbert space: A theoretical connection to functional linear regression", 
 author    = "Guochang Wang and Heng Lian", 
 year      = "2020", 
 doi       = "10.5705/ss.202017.0277",  
language  = "English", 
 volume    = "30", 
 pages     = "17--33", 
 journal   = "Statistica Sinica", 
 issn      = "1017-0405",
  publisher = "Academia Sinica * Institute of Statistical Science", 
 number    = "1", }


@article{Cook2019,
author = {R. Dennis Cook and Liliana Forzani},
title = {{Partial least squares prediction in high-dimensional regression}},
volume = {47},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {884--908},
keywords = {Abundant regressions, Dimension reduction, sparse regressions},
year = {2019},
doi = {10.1214/18-AOS1681},
URL = {https://doi.org/10.1214/18-AOS1681}
}
@article{LiDuan1989AoS,
author = {Ker-Chau Li and Naihua Duan},
title = {{Regression Analysis Under Link Violation}},
volume = {17},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1009--1052},
keywords = {$M$-estimate, adaptive estimation, elliptically symmetric design, exponential family, Fisher consistency, GLM, link violation, overdispersion, robustness, semiparametric models},
year = {1989},
doi = {10.1214/aos/1176347254},
URL = {https://doi.org/10.1214/aos/1176347254}
}
@article{JiangYuWang2014AoS,
author = {Ci-Ren Jiang and Wei Yu and Jane-Ling Wang},
title = {{Inverse regression for longitudinal data}},
volume = {42},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {563--591},
keywords = {Covariance operator, Dimension reduction, Functional data analysis, local polynomial smoothing, regularization, sparse data},
year = {2014},
doi = {10.1214/13-AOS1193},
URL = {https://doi.org/10.1214/13-AOS1193}
}
@article{ChenHallMuller2011AoS,
author = {Dong Chen and Peter Hall and Hans-Georg M{\"u}ller},
title = {{Single and multiple index functional regression models with nonparametric link}},
volume = {39},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1720--1747},
keywords = {Functional data analysis, generalized functional linear model, prediction, smoothing},
year = {2011},
doi = {10.1214/11-AOS882},
URL = {https://doi.org/10.1214/11-AOS882}
}
@article{HsingRen2009AoS,
author = {Tailen Hsing and Haobo Ren},
title = {{An RKHS formulation of the inverse regression dimension-reduction problem}},
volume = {37},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {726--755},
keywords = {Functional data analysis, sliced inverse regression},
year = {2009},
doi = {10.1214/07-AOS589},
URL = {https://doi.org/10.1214/07-AOS589}
}




@article{LiSong2022AoS,
author = {Bing Li and Jun Song},
title = {{Dimension reduction for functional data based on weak conditional moments}},
volume = {50},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {107--128},
keywords = {Carleman operator, Function-on-function regression, weak average variance estimate, weak conditional moment, weak directional regression, weak inverse regression estimate},
year = {2022},
doi = {10.1214/21-AOS2091},
URL = {https://doi.org/10.1214/21-AOS2091}
}
@article{LiSong2017AoS,
author = {Bing Li and Jun Song},
title = {{Nonlinear sufficient dimension reduction for functional data}},
volume = {45},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {1059--1095},
keywords = {convergence rate, handwriting data, linear operator, ‎reproducing kernel Hilbert ‎space, Sliced Average Variance Estimator, sliced inverse regression, speech recognition},
year = {2017},
doi = {10.1214/16-AOS1475},
URL = {https://doi.org/10.1214/16-AOS1475}
}

@article{Forzani2007,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24307695},
 abstract = {Estimation in the context of functional data analysis is almost always non-parametric, since the object to be estimated lives in an infinite dimensional space. That is the case for the functional linear model with a real response and a process as covariables. In a recent paper Ferré and Yao state that the estimation of the Effective Dimension Reduction (EDR) subspace via SIR has parametric order. We show that a strong condition is needed for their statement to be true.},
 author = {Liliana Forzani and R. Dennis Cook},
 journal = {Statistica Sinica},
 number = {4},
 pages = {1677--1681},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {A NOTE ON SMOOTHED FUNCTIONAL INVERSE REGRESSION},
 urldate = {2024-02-04},
 volume = {17},
 year = {2007}
}
@article{FerreYaoCook2010,
 ISSN = {10170405, 19968507},
 URL = {http://www.jstor.org/stable/24308989},
 abstract = {Ferré and Yao (2005, 2007) proposed a method to estimate the Effective Dimension Reduction space in functional sliced inverse regression. Their approach did not require the inversion of the variance-covariance operator of the explanatory variables, and it allowed them to get √n consistent estimators in the functional case. In those papers there is a mistake. In this note we show that, in general, the approach does not give an estimator of the SIR subspace. We also give necessary and sufficient conditions for this to be true.},
 author = {R. D. Cook and L. Forzani and A. F. Yao},
 journal = {Statistica Sinica},
 number = {1},
 pages = {235--238},
 publisher = {Institute of Statistical Science, Academia Sinica},
 title = {NECESSARY AND SUFFICIENT CONDITIONS FOR CONSISTENCY OF A METHOD FOR SMOOTHED FUNCTIONAL INVERSE REGRESSION},
 urldate = {2024-02-04},
 volume = {20},
 year = {2010}
}


@article{DauxoisFerreYao2001,
title = {Un modèle semi-paramétrique pour variables aléatoires hilbertiennes},
journal = {Comptes Rendus de l'Académie des Sciences - Series I - Mathématiques},
volume = {333},
number = {10},
pages = {947-952},
year = {2001},
issn = {0764-4442},
doi = {https://doi.org/10.1016/S0764-4442(01)02163-2},
url = {https://www.sciencedirect.com/science/article/pii/S0764444201021632},
author = {Jacques Dauxois and Louis Ferré and Anne-Françoise Yao},
abstract = {Résumé
Dans cette Note nous présentons un modèle de régression semi-paramétrique pour des variables aléatoires hilbertiennes, la partie «paramétrique » désignant une composante linéaire du modèle, par analogie avec la terminologie usuelle en dimension finie. Sous certaines conditions, nous proposons une méthode d'estimation de cette composante linéaire. Nous montrons que cette approche correspond à une généralisation de la méthode de régression inverse par tranches connue dans le cadre de la statistique multivariée. Cependant, dans le cadre fonctionnel, la mise en oeuvre de cette méthode nécessite quelques adaptations et nous présentons un résultat de convergence pour les estimateurs utilisés alors.
This Note deals with a semi-parametric model for Hilbertian random variables. The model is said semi-parametric by analogy with the finite dimensional case since the model involves a composition of any measurable mapping with a linear mapping which represents the “parametric” part. Under mild conditions, we derive a way for estimating this linear component in a particular case. We show that this method is actually a generalization of Li's Sliced Inverse Regression. However, in the Hilbertian context, SIR requires some adaptations of the estimation procedure and results concerning the consistency of the proposed estimates are given.}
}
@article{Preda2005,
title = {{PLS} regression on a stochastic process},
journal = {Computational Statistics \& Data Analysis},
volume = {48},
number = {1},
pages = {149--158},
year = {2005},
issn = {0167-9473},
doi = {https://doi.org/10.1016/j.csda.2003.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0167947303002366},
author = {C. Preda and G. Saporta},
keywords = {PLS regression, Stochastic process, Escoufier's operator, Principal component analysis},
abstract = {Partial least squares (PLS) regression on an L2-continuous stochastic process is an extension of the finite set case of predictor variables. The PLS components existence as eigenvectors of some operator and convergence properties of the PLS approximation are proved. The results of an application to stock-exchange data will be compared with those obtained by other methods.}
}
@article{LeeLi2022AoS,
author = {Kuang-Yao Lee and Lexin Li},
title = {{Functional sufficient dimension reduction through average Fréchet derivatives}},
volume = {50},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {904--929},
keywords = {consistency, exhaustiveness, Functional central mean subspace, functional central subspace, Function-on-function regression, ‎reproducing kernel Hilbert ‎space, unbiasedness},
year = {2022},
doi = {10.1214/21-AOS2131},
URL = {https://doi.org/10.1214/21-AOS2131}
}
@book{bochner,
author="Hyt{\"o}nen, Tuomas
and van Neerven, Jan
and Veraar, Mark
and Weis, Lutz",
title="Analysis in Banach Spaces. Volume I: Martingales and Littlewood-Paley Theory",
year="2016",
publisher="Springer International Publishing",
address="Cham",
abstract="This chapter sets up the general framework in which we work throughout these volumes. After introducing the relevant notions of measurability for functions taking values in a Banach space, we proceed to define the Bochner integral and the Bochner spaces Lp(S;X), which are the vector-valued counterparts of the Lebesgue integral and the classical Lp-spaces, respectively. We also briefly discuss the weaker Pettis integral. The chapter concludes with a detailed investigation of duality of the Bochner spaces and the related Radon--Nikod{\'y}m property.",
isbn="978-3-319-48520-1",
doi="10.1007/978-3-319-48520-1_1",
url="https://doi.org/10.1007/978-3-319-48520-1_1"
}


@book{Support_Vector_Machines,
author = {Steinwart, Ingo and Christmann, Andreas},
title = {Support Vector Machines},
year = {2008},
isbn = {0387772413},
publisher = {Springer Publishing Company, Incorporated},
edition = {1st},
abstract = {This book explains the principles that make support vector machines (SVMs) a successful modelling and prediction tool for a variety of applications. The authors present the basic ideas of SVMs together with the latest developments and current research questions in a unified style. They identify three reasons for the success of SVMs: their ability to learn well with only a very small number of free parameters, their robustness against several types of model violations and outliers, and their computational efficiency compared to several other methods. Since their appearance in the early nineties, support vector machines and related kernel-based methods have been successfully applied in diverse fields of application such as bioinformatics, fraud detection, construction of insurance tariffs, direct marketing, and data and text mining. As a consequence, SVMs now play an important role in statistical machine learning and are used not only by statisticians, mathematicians, and computer scientists, but also by engineers and data analysts. The book provides a unique in-depth treatment of both fundamental and recent material on SVMs that so far has been scattered in the literature. The book can thus serve as both a basis for graduate courses and an introduction for statisticians, mathematicians, and computer scientists. It further provides a valuable reference for researchers working in the field. The book covers all important topics concerning support vector machines such as: loss functions and their role in the learning process; reproducing kernel Hilbert spaces and their properties; a thorough statistical analysis that uses both traditional uniform bounds and more advanced localized techniques based on Rademacher averages and Talagrand's inequality; a detailed treatment of classification and regression; a detailed robustness analysis; and a description of some of the most recent implementation techniques. To make the book self-contained, an extensive appendix is added which provides the reader with the necessary background from statistics, probability theory, functional analysis, convex analysis, and topology.}
}
@article{DelaigleHall2012AoS,
author = {Aurore Delaigle and Peter Hall},
title = {{Methodology and theory for partial least squares applied to functional data}},
volume = {40},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {322--352},
keywords = {central limit theorem, computational algorithm, consistency, Convergence rates, functional linear models, generalized Fourier basis, principal components, projection, stochastic expansion},
year = {2012},
doi = {10.1214/11-AOS958},
URL = {https://doi.org/10.1214/11-AOS958}
}
@article{FerreYao2003,
author = {L. Ferré and A. F. Yao},
title = {Functional sliced inverse regression analysis},
journal = {Statistics},
volume = {37},
number = {6},
pages = {475-488},
year = {2003},
publisher = {Taylor & Francis},
doi = {10.1080/0233188031000112845},
URL = {https://doi.org/10.1080/0233188031000112845},
eprint = {https://doi.org/10.1080/0233188031000112845}
}
@article{Preda2002,
  TITLE = {{R{\'e}gression PLS sur un processus stochastique}},
  AUTHOR = {Preda, Cristian and Saporta, Gilbert},
  URL = {https://cnam.hal.science/hal-02507754},
  JOURNAL = {{Revue de Statistique Appliqu{\'e}e}},
  PUBLISHER = {{Soci{\'e}t{\'e} fran{\c c}aise de statistique}},
  VOLUME = {50},
  NUMBER = {2},
  PAGES = {27-45},
  YEAR = {2002},
  PDF = {https://cnam.hal.science/hal-02507754/file/RSA_2002__50_2_27_0.pdf},
  HAL_ID = {hal-02507754},
  HAL_VERSION = {v1},
}
@article{Preda2016,
title = {Penalized versions of functional {PLS} regression},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {154},
pages = {80-92},
year = {2016},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2016.03.013},
url = {https://www.sciencedirect.com/science/article/pii/S0169743916300491},
author = {A.M. Aguilera and M.C. Aguilera-Morillo and C. Preda},
keywords = {PLS, Functional data, Penalized splines, Basis representation},
abstract = {Least squares estimation of the functional linear regression model with scalar response is an ill-posed problem due to the infinite dimension of the functional predictor. Dimension reduction approaches as principal component regression or partial least squares regression are proposed and widely used in applications. In both cases the interpretation of the model could be difficult because of the roughness of the coefficient regression function. In this paper, two penalized estimations of this model based on modifying the partial least squares criterion with roughness penalties for the weight functions are proposed. One introduces the penalty in the definition of the norm in the functional space, and the other one in the cross-covariance operator. A simulation study and several applications on real data show the efficiency of the penalized approaches with respect to the non-penalized ones.}
}

@article{tian2023functional,
      title={Functional Slicing-free Inverse Regression via Martingale Difference Divergence Operator}, 
      author={Songtao Tian and Zixiong Yu and Rui Chen},
      year={2023},
      journal={arXiv:2307.12537},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}
@article{chen2023optimality,
      title={On the Optimality of Functional Sliced Inverse Regression}, 
      author={Rui Chen and Songtao Tian and Dongming Huang and Qian Lin and Jun S. Liu},
      year={2023},
      journal={arXiv:2307.02777},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}
@article{chatla2024inverse,
      title={Inverse regression for spatially distributed functional data}, 
      author={Suneel Babu Chatla and Ruiqi Liu},
      year={2024},
      journal={arXiv:2402.03206},
      archivePrefix={arXiv},
      primaryClass={math.ST}
}
@unpublished{huang2023sliced,
      title={Sliced Inverse Regression with Large Structural Dimensions}, 
      author={Dongming Huang and Songtao Tian and Qian Lin},
      year={2023},
      note={arXiv:2305.04340}}
}
@book{bingham_goldie_teugels_1987,
  title={Regular Variation},
  author={Bingham, N.H. and Goldie, C.M. and Teugels, J.L.},
  number={n°~1},
  isbn={9780521379434},
  lccn={86284221},
  series={Encyclopedia of Mathematics and its Applications},
  url={https://books.google.fr/books?id=VCU5D4jMfiEC},
  year={1989},
  publisher={Cambridge University Press}
}

@article{Lin2021AoS,
author = {Qian Lin and Xinran Li and Dongming Huang and Jun S. Liu},
title = {{On the optimality of sliced inverse regression in high dimensions}},
volume = {49},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {1--20},
keywords = {Optimal rates, semidefinite positive programming, sliced inverse regression, sufficient dimension reduction},
year = {2021},
doi = {10.1214/19-AOS1813},
URL = {https://doi.org/10.1214/19-AOS1813}
}

@article{Lin2018AoS,
author = {Qian Lin and Zhigen Zhao and Jun S. Liu},
title = {{On consistency and sparsity for sliced inverse regression in high dimensions}},
volume = {46},
journal = {The Annals of Statistics},
number = {2},
publisher = {Institute of Mathematical Statistics},
pages = {580--610},
keywords = {Dimension reduction, Random matrix theory, sliced inverse regression},
year = {2018},
doi = {10.1214/17-AOS1561},
URL = {https://doi.org/10.1214/17-AOS1561}
}


@book{Cook1998,
title = "Regression Graphics: Ideas for Studying Regressions Through Graphics",
author = "Cook, {R. D.}",
year = "1998",
language = "English",
publisher = "Wiley",
}
@article{Wold1975,
title={Soft Modelling by Latent Variables: The Non-Linear Iterative Partial Least Squares (NIPALS) Approach}, 
volume={12}, 
DOI={10.1017/S0021900200047604},
number={S1}, 
journal={Journal of Applied Probability},
author={Wold, Herman},
year={1975}, 
pages={117–142}
}

@article{Bousebata2023,
  TITLE = {{Extreme Partial Least-Squares}},
  AUTHOR = {Bousebata, Meryem and Enjolras, Geoffroy and Girard, St{\'e}phane},
  URL = {https://inria.hal.science/hal-03165399},
  JOURNAL = {{Journal of Multivariate Analysis}},
  PUBLISHER = {{Elsevier}},
  VOLUME = {194},
  PAGES = {105101},
  YEAR = {2023},
  DOI = {10.1016/j.jmva.2022.105101},
  KEYWORDS = {Extreme-value analysis ; Dimension reduction ; Non-linear inverse regression ; Partial Least Squares},
  PDF = {https://inria.hal.science/hal-03165399v3/file/Extreme_PLS_JMVA.pdf},
  HAL_ID = {hal-03165399},
  HAL_VERSION = {v3},
}

@article{ag2020estimation,
  title={Estimation of extreme quantiles from heavy-tailed distributions in a location-dispersion regression model},
  author={Ahmad, Aboubacr{\`e}ne Ag and Diop, Aliou and Girard, St{\'e}phane and Usseglio-Carleve, Antoine},
  journal={Electron. J. Stat.},
  volume={14},
  number={2},
  pages={4421--4456},
  year={2020},
  publisher={Institute of Mathematical Statistics and Bernoulli Society}
}

@article{bhattacharya1990kernel,
  title={Kernel and nearest-neighbor estimation of a conditional quantile},
  author={Bhattacharya, Pallab K and Gangopadhyay, Ashis K},
  journal={Ann. Stat.},
  pages={1400--1415},
    volume={18},
  number={3},
  year={1990},
  publisher={JSTOR}
}

@article{beirlant2004regression,
  title={Local polynomial maximum likelihood estimation for {P}areto-type distributions},
  author={Beirlant, Jan and Goegebeur, Yuri},
  journal={J. Multivariate Anal.},
  volume={89},
  number={1},
  pages={97--118},
  year={2004},
  publisher={Elsevier}
}

@book{beigoesegteu2004,
  title={Statistics of extremes: theory and applications},
  author={Beirlant, Jan and Goegebeur, Yuri and Segers, Johan and Teugels, Jozef L},
  volume={558},
  year={2004},
  publisher={John Wiley \& Sons, New-York}
}

@article{BGG2009,
  title={Gaussian regularized sliced inverse regression},
  author={Bernard-Michel, Caroline and Gardes, Laurent and Girard, St{\'e}phane},
  journal={Stat. Comput.},
  volume={19},
  number={1},
  pages={85--98},
  year={2009},
  publisher={Springer}
}

@book{Bill1995,
  title={Measure and Probability (third edition)},
  author={Billingsley, Patrick},
  year={1995},
  publisher={John Wiley \& Sons, New-York}
}

@book{Bing1989,
  author={Bingham, N.H. and Goldie, C.M. and Teugels, J.L.},
    title={Regular Variation},
    publisher={Cambridge University Press},
    year={1987},
    volume={27},
    series={Encyclopedia of Mathematics and its application}
  }
}

@article{Cai,
  title={Estimation of the marginal expected shortfall: the mean when a related variable is extreme},
  author={Cai, Juan-Juan and Einmahl, John HJ and de Haan, Laurens and Zhou, Chen},
  journal={J. Roy. Stat. Soc. B},
  volume={77},
  number={2},
  pages={417--442},
  year={2015},
  publisher={Wiley Online Library}
}

@article{Cattell,
  title={The scree test for the number of factors},
  author={Cattell, Raymond B},
  journal={Multivar. Behav. Res.},
  volume={1},
  number={2},
  pages={245--276},
  year={1966},
  publisher={Taylor \& Francis}
}

@article{chung2010sparse,
  title={Sparse partial least squares regression for simultaneous dimension reduction and variable selection},
  author={Chun, Hyonho and Kele{\c{s}}, S{\"u}nd{\"u}z},
  journal={Journal of the Royal Statistical Society. Series~B (Statistical Methodology)},
  volume={72},
  number={1},
  pages={3--25},
  year={2010},
  publisher={Wiley Online Library}
}

@article{chavez2005generalized,
  title={Generalized additive modelling of sample extremes},
  author={Chavez-Demoulin, Val{\'e}rie and Davison, Anthony C},
  journal={Journal of the Royal Statistical Society. Series~C (Applied Statistics)},
  volume={54},
  number={1},
  pages={207--222},
  year={2005},
  publisher={Wiley Online Library}
}

@article{chernozhukov2005extremal,
  title={Extremal quantile regression},
  author={Chernozhukov, Victor},
  journal={The Annals of Statistics},
  volume={33},
  number={2},
  pages={806--839},
  year={2005},
  publisher={Institute of Mathematical Statistics}
}
@article{chiancone2017student,
  title={Student sliced inverse regression},
  author={Chiancone, Alessandro and Forbes, Florence and Girard, St{\'e}phane},
  journal={Comput. Stat. Data An.},
  volume={113},
  pages={441--456},
  year={2017},
  publisher={Elsevier}
}

@article{Cook2007,
  title={Fisher lecture: Dimension reduction in regression},
  author={Cook, R Dennis},
  journal={Statistical Science},
  volume={22},
  number={1},
  pages={1--26},
  year={2007},
  publisher={Institute of Mathematical Statistics}
}

@article{Cook2018,
  title={Big data and partial least-squares prediction},
  author={Cook, R Dennis and Forzani, Liliana},
  journal={The Canadian Journal of Statistics},
  volume={46},
  number={1},
  pages={62--78},
  year={2018},
  publisher={Wiley Online Library}
}


@article{Cool,
  title={Decompositions of dependence for high-dimensional extremes},
  author={Cooley, Daniel and Thibaud, Emeric},
  journal={Biometrika},
  volume={106},
  number={3},
  pages={587--604},
  year={2019},
  publisher={Oxford University Press}
}

@article{coudret2014new,
  title={A new sliced inverse regression method for multivariate response},
  author={Coudret, Rapha{\"e}l and Girard, St{\'e}phane and Saracco, Jerome},
  journal={Comput. Stat. Data An.},
  volume={77},
  pages={285--299},
  year={2014},
  publisher={Elsevier}
}

@article{Daouia2011,
  title={Kernel estimators of extreme level curves},
  author={Daouia, Abdelaati and Gardes, Laurent and Girard, St{\'e}phane and Lekina, Alexandre},
  journal={Test},
  volume={20},
  number={2},
  pages={311--333},
  year={2011},
  publisher={Springer}
}

@article{daouia2013kernel,
  title={On kernel smoothing for extremal quantile regression},
  author={Daouia, Abdelaati and Gardes, Laurent and Girard, St{\'e}phane},
  journal={Bernoulli},
  volume={19},
  number={5B},
  pages={2557--2589},
  year={2013},
  publisher={Bernoulli Society for Mathematical Statistics and Probability}
}

@article{davison2000local,
  title={Local likelihood smoothing of sample extremes},
  author={Davison, Anthony C and Ramesh, NI},
  journal={Journal of the Royal Statistical Society. Series~B (Statistical Methodology)},
  volume={62},
  number={1},
  pages={191--208},
  year={2000},
  publisher={Wiley Online Library}
}
@article{davison1990models,
  title={Models for exceedances over high thresholds},
  author={Davison, Anthony C and Smith, Richard L},
  journal={Journal of the Royal Statistical Society. Series~B (Statistical Methodology)},
  volume={52},
  number={3},
  pages={393--425},
  year={1990},
  publisher={JSTOR}
}
@article{Drees2019,
  title={Principal component analysis for multivariate extremes},
  author={Drees, Holger and Sabourin, Anne},
  journal={Electronic Journal of Statistics},
  volume={15},
  number={1},
  pages={908--943},
  year={2021},
  publisher={Institute of Mathematical Statistics and Bernoulli Society}
}

@article{elmethni,
  title={Non-parametric Estimation of Extreme Risk Measures from Conditional Heavy-tailed Distributions},
  author={El-Methni, Jonathan and Gardes, Laurent and Girard, Stephane},
  journal={Scandinavian Journal of Statistics},
  volume={41},
  number={4},
  pages={988--1012},
  year={2014},
  publisher={Wiley Online Library}
}

@article{frank1993statistical,
  title={A statistical view of some chemometrics regression tools},
  author={Frank, LLdiko E and Friedman, Jerome H},
  journal={Technometrics},
  volume={35},
  number={2},
  pages={109--135},
  year={1993},
  publisher={Taylor \& Francis}
}

@book{friedman2001elements,
  title={The elements of statistical learning},
  author={Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year={2001},
  publisher={Springer Series in Statistics, New-York}
}

@article{Gardes2018,
  title={Tail dimension reduction for extreme quantile estimation},
  author={Gardes, Laurent},
  journal={Extremes},
  volume={21},
  number={1},
  pages={57--95},
  year={2018},
  publisher={Springer}
}

@article{GG2010,
  title={Conditional extremes from heavy-tailed distributions: An application to the estimation of extreme rainfall return levels},
  author={Gardes, L. and Girard, S.},
  journal={Extremes},
  volume={13},
  number={2},
  pages={177--204},
  year={2010}
}


@article{thisisus,
  title={Advanced topics in Sliced Inverse Regression},
  author={Girard, St{\'e}phane and Lorenzo, Hadrien and Saracco, J{\'e}r{\^o}me},
  journal={J. Multivariate Anal.},
  volume={188},
  pages={104852},
  year={2022},
  publisher={Elsevier}
}

@article{AOS,
  title={Extreme conditional expectile estimation in heavy-tailed heteroscedastic regression models},
  author={Girard, St{\'e}phane and Stupfler, Gilles and Usseglio-Carleve, Antoine},
  journal={Ann. Stat.},
  volume={49},
  number={6},
  pages={3358--3382},
  year={2021},
  publisher={Institute of Mathematical Statistics}
}


@article{STCO7,
author="J. Arbel and S. Girard and H. Lorenzo",
title     = "Shrinkage for {E}xtreme {P}artial {L}east {S}quares",
journal= "Statistics and Computing",
 volume={34},
 pages=181,
year      = "2024"
}

@article{goegebeur2014nonparametric,
  title={Nonparametric regression estimation of conditional tails: the random covariate case},
  author={Goegebeur, Yuri and Guillou, Armelle and Schorgen, Antoine},
  journal={Statistics},
  volume={48},
  number={4},
  pages={732--755},
  year={2014},
  publisher={Taylor \& Francis}
}

@book{Haan2007,
  title={Extreme value theory: an introduction},
  author={de Haan, L. and Ferreira, A.},
  year={2006},
  publisher={Springer Science \& Business Media, New-York}
}

@article{hall2000nonparametric,
  title={Nonparametric analysis of temporal trend when fitting parametric models to extreme-value data},
  author={Hall, Peter and Tajvidi, Nader},
  journal={Stat. Sci.},
  volume={15},
  number={2},
  pages={153--167},
  year={2000},
  publisher={JSTOR}
}

@article{hardle1989investigating,
  title={Investigating smooth multiple regression by the method of average derivatives},
  author={H{\"a}rdle, Wolfgang and Stoker, Thomas M},
  journal={{Journal of the American Statistical Association}},
  volume={84},
  number={408},
  pages={986--995},
  year={1989},
  publisher={Taylor \& Francis}
}
@article{he1998bivariate,
  title={Bivariate quantile smoothing splines},
  author={He, Xuming and Ng, Pin and Portnoy, Stephen},
  journal={J. Roy. Stat. Soc. B},
  volume={60},
  number={3},
  pages={537--550},
  year={1998},
  publisher={Wiley Online Library}
}

@article{helland1990partial,
  title={Partial least squares regression and statistical models},
  author={Helland, Inge S},
  journal={Scand. J. Stat.},
   volume={17},
  number={2},
  pages={97--114},
  year={1990},
  publisher={JSTOR}
}
@article{Hill,
  title={A simple general approach to inference about the tail of a distribution},
  author={Hill, B.},
  journal={The Annals of Statistics},
  volume={3},
  number={5},
  pages={1163--1174},
  year={1975}
}
@article{hoerl1970ridge,
  title={Ridge regression: applications to nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={69--82},
  year={1970},
  publisher={Taylor \& Francis}
}
@book{horowitz2009,
  title={Semiparametric and nonparametric methods in econometrics},
  author={Horowitz, Joel L},
  volume={12},
  year={2009},
  publisher={Springer, New-York}
}
@article{jagger2009modeling,
  title={Modeling tropical cyclone intensity with quantile regression},
  author={Jagger, Thomas H and Elsner, James B},
  journal={Int. J. Climatol.},
  volume={29},
  number={10},
  pages={1351--1361},
  year={2009},
  publisher={Wiley Online Library}
}
@article{koenker1978regression,
  title={Regression quantiles},
  author={Koenker, Roger and Bassett Jr, Gilbert},
  journal={Econometrica},
  pages={33--50},
  volume={46},
  number={1},
  year={1978},
  publisher={JSTOR}
}
@article{kong2012single,
  title={A single-index quantile regression model and its estimation},
  author={Kong, Efang and Xia, Yingcun},
  journal={Economet. Theor.},
  volume={28},
  number={4},
  pages={730--768},
  year={2012},
  publisher={Cambridge University Press}
}
@article{kyungjoon,
  title={Nonparametric kernel regression estimation near endpoints},
  author={Kyung-Joon, Cha and Schucany, William R},
  journal={J. Stat. Plan. Infer.},
  volume={66},
  number={2},
  pages={289--304},
  year={1998},
  publisher={Elsevier}
}
@article{Li1991,
  title={Sliced inverse regression for dimension reduction},
  author={Li, Ker-Chau},
  journal={{Journal of the American Statistical Association}},
  volume={86},
  number={414},
  pages={316--327},
  year={1991},
  publisher={Taylor \& Francis}
}


@article{li2007partial,
  title={Partial inverse regression},
  author={Li, Lexin and Cook, R Dennis and Tsai, Chih-Ling},
  journal={Biometrika},
  volume={94},
  number={3},
  pages={615--625},
  year={2007},
  publisher={Oxford University Press}
}

@article{li2012maxi,
  title={Maximum likelihood estimators in a two step model for {PLS}},
  author={Li, Ying and von Rosen, Dietrich},
  journal={Commun. Stat. Theory Methods},
  volume={41},
  number={13-14},
  pages={2503--2511},
  year={2012},
  publisher={Taylor \& Francis}
}

@book{martens1992multivariate,
  title={Multivariate calibration},
  author={Martens, Harald and Naes, Tormod},
  year={1992},
  publisher={John Wiley \& Sons, New-York}
}

@article{meligkotsidou2009quantile,
  title={Quantile regression analysis of hedge fund strategies},
  author={Meligkotsidou, Loukia and Vrontos, Ioannis D and Vrontos, Spyridon D},
  journal={J. Empir. Finance},
  volume={16},
  number={2},
  pages={264--279},
  year={2009},
  publisher={Elsevier}
}
@article{naik2000partial,
  title={Partial least squares estimator for single-index models},
  author={Naik, Prasad and Tsai, Chih-Ling},
  journal={Journal of the Royal Statistical Society. Series~B (Statistical Methodology)},
  volume={62},
  number={4},
  pages={763--771},
  year={2000},
  publisher={Wiley Online Library}
}

@book{Nelsen2007,
  title={An introduction to copulas},
  author={Nelsen, Roger B},
  year={2007},
  publisher={Springer Science \& Business Media, New-York}
}

@article{powell1989semiparametric,
  title={Semiparametric estimation of index coefficients},
  author={Powell, James L and Stock, James H and Stoker, Thomas M},
  journal={Econometrica},
  volume={57},
  number={6},
  pages={1403--1430},
  year={1989},
  publisher={JSTOR}
}
@article{Saracco,
  title={An asymptotic theory for sliced inverse regression},
  author={Saracco, Jerome},
  journal={Commun. Stat. Theory Methods},
  volume={26},
  number={9},
  pages={2141--2171},
  year={1997},
  publisher={Taylor \& Francis}
}


@article{smith1989extreme,
  title={Extreme value analysis of environmental time series: an application to trend detection in ground-level ozone},
  author={Smith, Richard L},
  journal={Stat. Sci.},
  volume={4},
  number={4},
  pages={367--377},
  year={1989},
  publisher={JSTOR}
}

@article{smith2,
  title={Crop insurance, moral hazard, and agricultural chemical use},
  author={Smith, Vincent H and Goodwin, Barry K},
  journal={Am. J. Agr. Econ.},
  volume={78},
  number={2},
  pages={428--438},
  year={1996},
  publisher={Wiley Online Library}
}
@article{stone1990continuum,
  title={Continuum regression: cross-validated sequentially constructed prediction embracing ordinary least squares, partial least squares and principal components regression},
  author={Stone, Mervyn and Brooks, Rodney J},
  journal={J. Roy. Stat. Soc. B},
  volume={52},
  number={2},
  pages={237--258},
  year={1990},
  publisher={Wiley Online Library}
}
@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the {L}asso},
  author={Tibshirani, Robert},
  journal={J. Roy. Stat. Soc. B},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Wiley Online Library}
}
@article{tibshirani2005sparsity,
  title={Sparsity and smoothness via the fused lasso},
  author={Tibshirani, Robert and Saunders, Michael and Rosset, Saharon and Zhu, Ji and Knight, Keith},
  journal={J. Roy. Stat. Soc. B},
  volume={67},
  number={1},
  pages={91--108},
  year={2005},
  publisher={Wiley Online Library}
}

@article{wang2020extreme,
  title={Extreme quantile estimation based on the tail single-index model},
  author={Xu, Wen and Li, D and Wang, H},
  journal={Statistica Sinica},
   volume={32},
  pages={1--22},
  year={2020}
}

@article{wang2009spline,
  title={Spline estimation of single-index models},
  author={Wang, Li and Yang, Lijian},
  journal={Stat. Sinica},
  volume={19},
  pages={765--783},
  year={2009},
  publisher={JSTOR}
}

@article{wold1975soft,
  title={Soft modelling by latent variables: the non-linear iterative partial least squares (NIPALS) approach},
  author={Wold, Herman},
  journal={J. Appl. Probab.},
  volume={12},
  number={S1},
  pages={117--142},
  year={1975},
  publisher={Cambridge University Press}
}
@article{wu2008kernel,
  title={Kernel sliced inverse regression with applications to classification},
  author={Wu, Han-Ming},
  journal={J. Comput. Graph. Stat.},
  volume={17},
  number={3},
  pages={590--610},
  year={2008},
  publisher={Taylor \& Francis}
}
@article{wu2010single,
  title={Single-index quantile regression},
  author={Wu, Tracy Z and Yu, Keming and Yu, Yan},
  journal={J. Multivariate Anal.},
  volume={101},
  number={7},
  pages={1607--1621},
  year={2010},
  publisher={Elsevier}
}
@article{yu2002penalized,
  title={Penalized spline estimation for partially linear single-index models},
  author={Yu, Yan and Ruppert, David},
  journal={{Journal of the American Statistical Association}},
  volume={97},
  number={460},
  pages={1042--1054},
  year={2002},
  publisher={Taylor \& Francis}
}
@article{zhu,
  title={Semiparametric quantile regression with high-dimensional covariates},
  author={Zhu, Liping and Huang, Mian and Li, Runze},
  journal={Stat. Sinica},
  volume={22},
  number={4},
  pages={1379--1401},
  year={2012},
  publisher={NIH Public Access}
}
@article{zou2005regularization,
  title={Regularization and variable selection via the elastic net},
  author={Zou, Hui and Hastie, Trevor},
  journal={J. Roy. Stat. Soc. B},
  volume={67},
  number={2},
  pages={301--320},
  year={2005},
  publisher={Wiley Online Library}
}
















































































































