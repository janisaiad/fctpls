{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_boUx_3FvO4O"
   },
   "outputs": [],
   "source": [
    "###################### Magic commands\n",
    "\n",
    "##%%timeit -n 1 -r 1\n",
    "#%%time\n",
    "import time\n",
    "#start = time.time()\n",
    "\n",
    "###################### at the end\n",
    "\n",
    "#end = time.time()\n",
    "#print(end - start)\n",
    "\n",
    "###################### Packages\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "#import Pyarrow # for pandas\n",
    "import scipy.special\n",
    "import math \n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from fctpls.utils import stooq_txt_to_df, stooq_to_notebook_format\n",
    "\n",
    "# we load stooq data (with\n",
    "# pip install fbm\n",
    "# from fbm import FBM\n",
    "\n",
    "###################### Options\n",
    "\n",
    "npr.seed(0)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#<\n",
    "#>\n",
    "\n",
    "############### Tools transfering numpy to numba\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def np_apply_along_axis_2darray(func1d, axis, arr):\n",
    "  assert arr.ndim == 2\n",
    "  assert axis in [0, 1]\n",
    "  if axis == 0:\n",
    "    result = np.empty(arr.shape[1])\n",
    "    for i in numba.prange(len(result)):\n",
    "      result[i] = func1d(arr[:, i])\n",
    "  else:\n",
    "    result = np.empty(arr.shape[0])\n",
    "    for i in numba.prange(len(result)):\n",
    "      result[i] = func1d(arr[i, :])\n",
    "  return result\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def np_mean_2darray(array, axis):\n",
    "  return np_apply_along_axis_2darray(np.mean, axis, array)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def np_std_2darray(array, axis):\n",
    "  return np_apply_along_axis_2darray(np.std, axis, array)\n",
    "\n",
    "################################################## Non-empty\n",
    "\n",
    "def check_cond(gamma,c,tau,q):\n",
    "    if 0<tau:\n",
    "        if gamma<1 and 0<gamma and 2<q and 0<c and 2*(c+tau)*gamma<1 and q*(1-2*tau*gamma)>2 and q*c*gamma>1 and tau <1/(2*gamma):\n",
    "            print('Valid!')\n",
    "        else:\n",
    "            print('Not valid!')\n",
    "    else:\n",
    "        if gamma<1 and 0<gamma and 2<q and 0<c and 2*(c+tau)*gamma<1 and q*c*gamma>1:\n",
    "            print('Valid!')\n",
    "        else:\n",
    "            print('Not valid!')        \n",
    "    return\n",
    "\n",
    "def check_cond_no_q(gamma,c,tau):\n",
    "    if gamma<1 and 0<gamma and 0<c and 2*(c+tau)*gamma<1:\n",
    "        print('Valid!')\n",
    "    else:\n",
    "        print('Not valid!')   \n",
    "    return\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def find_cond_all(h_gamma,h_c,h_tau,h_q,max_c,max_tau,max_q):\n",
    "    gamma_mesh = np.linspace(0.01,0.99,h_gamma)\n",
    "    c_mesh = np.linspace(0.1,max_c,h_c)\n",
    "    tau_mesh = np.linspace(-max_tau,max_tau,h_tau)\n",
    "    q_mesh = np.linspace(2.1,max_q,h_q)\n",
    "    for gamma_index in numba.prange(h_gamma):\n",
    "        for c_index in numba.prange(h_c): \n",
    "            for tau_index in numba.prange(h_tau):\n",
    "                for q_index in numba.prange(h_q):\n",
    "                    gamma=gamma_mesh[gamma_index]\n",
    "                    c=c_mesh[c_index]\n",
    "                    tau=tau_mesh[tau_index]\n",
    "                    q=q_mesh[q_index]\n",
    "                    if 0<tau:\n",
    "                        if 2<q and 0<c and 2*(c+tau)*gamma<1 and q*(1-2*tau*gamma)>2 and q*c*gamma>1:\n",
    "                            print([gamma, c, tau, q])\n",
    "                    else:\n",
    "                        if 2<q and 0<c and 2*(c+tau)*gamma<1 and q*c*gamma>1:\n",
    "                            print([gamma, c, tau, q])                        \n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_cond_no_q(grid_gamma,max_tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    c_mesh = np.arange(1,10)\n",
    "    tau_mesh = np.arange(-max_tau,max_tau+1)\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        for c_index in numba.prange(c_mesh.shape[0]): \n",
    "            for tau_index in numba.prange(tau_mesh.shape[0]):\n",
    "                gamma=gamma_mesh[gamma_index]\n",
    "                c=c_mesh[c_index]\n",
    "                tau=tau_mesh[tau_index]\n",
    "                if 2*(c+tau)*gamma<1:\n",
    "                    print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_gamma_no_q(grid_gamma,c,tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        gamma=gamma_mesh[gamma_index]\n",
    "        if 2*(c+tau)*gamma<1:\n",
    "            print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_cond_c_no_q(c,grid_gamma,max_tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    tau_mesh = np.arange(-max_tau,max_tau+1)\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        for tau_index in numba.prange(tau_mesh.shape[0]):\n",
    "            gamma=gamma_mesh[gamma_index]\n",
    "            tau=tau_mesh[tau_index]\n",
    "            if 2*(c+tau)*gamma<1:\n",
    "                print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_cond_c_tau_no_q(c,tau,grid_gamma,max_tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    tau_mesh = np.arange(-max_tau,max_tau+1)\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        for tau_index in numba.prange(tau_mesh.shape[0]):\n",
    "            gamma=gamma_mesh[gamma_index]\n",
    "            tau=tau_mesh[tau_index]\n",
    "            if 2*(c+tau)*gamma<1:\n",
    "                print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "################################################## Generating Data\n",
    "\n",
    "@numba.njit(parallel=False, fastmath=False)\n",
    "def Lomax_quantile_function(x,theta,s):  \n",
    "    return s*((1-x)**(-1/theta)-1)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def Pareto_quantile_function(x,gamma,s): # support is  {x \\ge s} and theta=1/\\gamma\n",
    "    return s*(1-x)**(-gamma)\n",
    "\n",
    "#The Burr distribution has survival distribution $\\bar{F}(y)=(1+y^\\rho)^{-\\theta} \\in 2\\RV_{-\\theta \\rho,-\\rho}$ where $x\\ge 0$ and $\\theta,\\rho>0$.\n",
    "@numba.njit(parallel=True, fastmath=False) # rho,theta positive\n",
    "def Burr_quantile_function(x,theta,rho): \n",
    "    return ((1-x)**(-1/theta)-1)**(1/rho)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func3(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.exp(-grid**2+grid)**2)/d)\n",
    "    return np.exp(-grid**2+grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func2(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.exp(-grid)**2)/d)\n",
    "    return np.exp(-grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.sin(2*np.pi*grid)**2)/d)\n",
    "    return np.sin(2*np.pi*grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func5(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.sin(1/(1/12+grid**2))/d))\n",
    "    return np.sin(1/(1/12+grid**2))/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func6(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.cos(2*np.pi*grid+np.sin(1/(grid+1/10)))/d))\n",
    "    return np.cos(2*np.pi*grid+np.sin(1/(grid+1/10)))/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func7(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.cos(2*np.pi*grid)**2)/d)\n",
    "    return np.cos(2*np.pi*grid)/norm\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func4(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.sin(2*np.pi*grid)**2)/d)\n",
    "    return np.sin(2*np.pi*grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def coeurjolly_cholesky_fbm_1D(d,H,sigma):\n",
    "    H2 = 2 * H\n",
    "    matcov = np.zeros((d-1,d-1))\n",
    "    for i in numba.prange(d-1):\n",
    "        for j in numba.prange(i,d-1):\n",
    "            r = (sigma**2)*(1/2)*(abs(i+1)**H2 + abs(j+1)**H2 - abs(j - i)**H2)\n",
    "            r = r/(d**H2)\n",
    "            matcov[i, j] = r\n",
    "            matcov[j, i] = matcov[i, j]\n",
    "    L = np.linalg.cholesky(matcov)\n",
    "    Z = npr.normal(0,1,size=(d - 1))\n",
    "    fBm = np.dot(L , Z)\n",
    "    #out=np.concatenate(([0], fBm))\n",
    "    # out=np.hstack(([0], fBm))\n",
    "    out= np.asarray([0] + list(fBm))\n",
    "    return out\n",
    "\n",
    "# @Article{RePEc:jss:jstsof:v:005:i07,\n",
    "#  author={Coeurjolly, Jean-Francois},\n",
    "#  title={{Simulation and identification of the fractional Brownian motion: a bibliographical and comparative study}},\n",
    "#  journal={Journal of Statistical Software},\n",
    "#  year=2000,\n",
    "#  volume={5},\n",
    "#  number={i07},\n",
    "#  pages={},\n",
    "#  month={},\n",
    "#  keywords={},\n",
    "#  doi={http://hdl.handle.net/10.18637/jss.v005.i07}\n",
    "#}\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def coeurjolly_cholesky_fbm_array(Z,H,sigma): # Z=npr.normal(0,1,size=(N,n,d - 1))\n",
    "    N=Z.shape[0]\n",
    "    n=Z.shape[1]\n",
    "    d=Z.shape[2]+1\n",
    "    out = np.zeros((N,n,d))\n",
    "    for p in numba.prange(N):\n",
    "        for q in numba.prange(n):    \n",
    "            H2 = 2 * H\n",
    "            matcov = np.zeros((d-1,d-1))\n",
    "            for i in numba.prange(d-1):\n",
    "                for j in numba.prange(i,d-1):\n",
    "                    r = (sigma**2)*(1/2)*(abs(i+1)**H2 + abs(j+1)**H2 - abs(j - i)**H2)\n",
    "                    r = r/(d**H2)\n",
    "                    matcov[i, j] = r\n",
    "                    matcov[j, i] = matcov[i, j]\n",
    "            L = np.linalg.cholesky(matcov)\n",
    "            fBm = np.dot(L , Z[p,q,:])\n",
    "            #out=np.concatenate(([0], fBm))\n",
    "            # out=np.hstack(([0], fBm))\n",
    "            out[p,q,:]= np.asarray([0] + list(fBm))\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def sigma(u,c,snr): \n",
    "    return (u**c)/snr\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def noise_mean(d,mu):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    return mu*grid\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu): #Z = npr.normal(0,1,size=(N,n,d - 1))  \n",
    "                                     #Y = Pareto_iterated_sample(N,n,theta,s)\n",
    "    N=Y.shape[0]\n",
    "    n=Y.shape[1]\n",
    "    d=Z.shape[2]+1\n",
    "    out = np.zeros((N,n,d))\n",
    "    H2 = 2 * H\n",
    "    matcov = np.zeros((d-1,d-1))\n",
    "    for p in numba.prange(N):\n",
    "        for q in numba.prange(n):\n",
    "            matcov = np.zeros((d-1,d-1))\n",
    "            for i in numba.prange(d-1):\n",
    "                for j in numba.prange(i,d-1):\n",
    "                    r = (sigma(Y[p,q],c,snr)**2)*(1/2)*(abs(i+1)**H2 + abs(j+1)**H2 - abs(j - i)**H2)\n",
    "                    r = r/(d**H2)\n",
    "                    matcov[i, j] = r\n",
    "                    matcov[j, i] = matcov[i, j]\n",
    "            L = np.linalg.cholesky(matcov)\n",
    "            fBm = np.dot(L , Z[p,q,:])\n",
    "            out[p,q,:]= np.asarray([0]+list(fBm)) + noise_mean(d,mu)\n",
    "    return out\n",
    "\n",
    "################################################## Estimation\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def esdf(data,x): # Empirical Survival Distribution Function of Y. Here, x.shape = (N,) or (N,n) is the threshold\n",
    "    # data is Y and data.shape = (N,n)\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    if x.ndim == 1:\n",
    "        indicator_matrix = np.transpose(np.where(np.transpose(data)>x,1,0)) # binary matrix with same shape as data representating the indicator matrix 1_{X_ij<x_j}\n",
    "    if x.ndim == 2:\n",
    "        indicator_matrix = np.where(data>x,1,0)\n",
    "    return np.sum(indicator_matrix,axis=1)/n # (N,)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def threshold_index(X,Y,Y_sort_index,tau,m,start): # 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    out=np.zeros((N,))\n",
    "    aux=concomittant_corr(X,Y,Y_sort_index,tau,m)[:,start:]\n",
    "    return start+np.argmax(aux,axis=1)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def threshold(X,Y,Y_sort_index,tau,m,start): # 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    y_matrix_out = np.zeros((N,n))\n",
    "    YY=np.copy(Y)\n",
    "    Y_sort=sort_2d_array(YY)\n",
    "    index = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "    for i in numba.prange(N):\n",
    "        y_matrix_out[i,:] = Y_sort[i,n-index[i]-1]*np.ones((n,))\n",
    "    return y_matrix_out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def fepls_weight(Y,y_matrix,nu): # Y of size (N,n)\n",
    "                             # y_matrix of shape (N,n), for instance y_matrix = y*np.ones((N,n)) where y threshold\n",
    "                             # nu is such that \\psi(x) = x^nu\n",
    "    N=Y.shape[0]\n",
    "    n=Y.shape[1]\n",
    "    out=np.zeros((N,))\n",
    "    aux = Y**nu # size (N,n) - \\psi(Y_i)\n",
    "    aux2 = np.multiply(aux,np.greater_equal(Y,y_matrix)) # size (N,n) - Product \\psi(Y_i)*1_{Y_i \\ge y}\n",
    "    return np.sum(aux2,axis=1)/n # size (N,)\n",
    "\n",
    "#@numba.njit(parallel=True, fastmath=False) # It seems that \"greater_equal\" and numba don't work well together\n",
    "def fepls(X,Y,y_matrix,tau): # X of size (N,n,d) and Y of size (N,n)\n",
    "                             # y_matrix of shape (N,n), for instance y_matrix = y*np.ones((N,n)) where y threshold\n",
    "                             # tau is the tail index of \\vfi\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    out=np.zeros((N,d))\n",
    "    for j in range(d):\n",
    "        aux = np.multiply(X[:,:,j],Y**tau) # size (N,n,d) - Product \\vfi(Y_i)*X_i\n",
    "        out2 = np.multiply(aux,np.greater_equal(Y,y_matrix)) # size (N,n) - Product \\vfi(Y_i)*X_i*1_{Y_i \\ge y}\n",
    "        out[:,j]= np.sum(out2,axis=1)/n # (N,d)\n",
    "    norms=np.sqrt(np.sum(out**2,axis=1)/d) # length (N,)\n",
    "    out2 =  out * (norms.reshape((norms.size, 1)))**(-1)\n",
    "    return out2 # size (N,d)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def fepls_numba(X,Y,y_matrix,tau): # X of size (N,n,d) and Y of size (N,n)\n",
    "                             # y_matrix of shape (N,n), for instance y_matrix = y*np.ones((N,n)) where y threshold\n",
    "                             # tau is the tail index of \\vfi\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    out=np.zeros((N,d))\n",
    "    for j in numba.prange(d):\n",
    "        aux = np.multiply(X[:,:,j],Y**tau) # size (N,n,d) - Product \\vfi(Y_i)*X_i\n",
    "        out2 = np.multiply(aux,np.greater_equal(Y,y_matrix)) # size (N,n) - Product \\vfi(Y_i)*X_i*1_{Y_i \\ge y}\n",
    "        out[:,j]= np.sum(out2,axis=1)/n # (N,d)\n",
    "    norms=np.sqrt(np.sum(out**2,axis=1)/d) # length (N,)\n",
    "    out2 =  out * (norms.reshape((norms.size, 1)))**(-1)\n",
    "    return out2 # size (N,d)\n",
    "\n",
    "# g(t)= t^c with c \\in \\{1/4,1/2,1,3/2\\} \n",
    "# X = g(Y)\\beta + \\eps\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def Hill(Y,int_seq): # Y of size (N,n), y number, int_seq is an intermediate sequence, ie such that int_seq << n\n",
    "    N=Y.shape[0]\n",
    "    n=Y.shape[1]\n",
    "    Y_ord=np.copy(Y)\n",
    "    Y_ord=np.sort(Y_ord) \n",
    "    Y_2=Y_ord[:,n-int_seq-1]\n",
    "    aux=Y_ord/Y_2[:, None]\n",
    "    out=np.log(aux[:,0:n-int_seq])\n",
    "    return (1/int_seq)*np.sum(out,axis=1) # size (N,)\n",
    "\n",
    "#### Same as np.sort for 2D arrays but works with numba njit+parallel\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def sort_2d_array(x):\n",
    "    n,m=np.shape(x)\n",
    "    for row in numba.prange(n):\n",
    "        x[row]=np.sort(x[row])\n",
    "    return x\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def hatbeta_dot_beta(X,Y,tau,l):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    y_array=np.zeros((N,n,np.arange(int(n/l)).size))\n",
    "    out=np.zeros((N,np.arange(int(n/l)).size))\n",
    "    YY=np.copy(Y)\n",
    "    for p in numba.prange(int(n/l)):\n",
    "        y_array[:,0,p]=sort_2d_array(YY)[:,n-l*p-1]\n",
    "        for k in numba.prange(N):\n",
    "            y_array[k,:,p]=y_array[k,0,p]\n",
    "        hat_beta=fepls_numba(X,Y,y_array[:,:,p],tau) \n",
    "        out[:,p]=(1/d)*np.sum(np.multiply(hat_beta,X[:,p,:]),axis=1) \n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def concomittant_corr(X,Y,Y_sort_index,tau,m): # 1\\le m \\le n # Y_sort_index = np.argsort(Y,axis=1)\n",
    "    N = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    d = X.shape[2]\n",
    "    out = np.zeros((N,m))\n",
    "    YY=np.copy(Y)\n",
    "    Y_sort=sort_2d_array(YY)\n",
    "    for k in numba.prange(m):\n",
    "        y_array = np.zeros((N,n,k+1))\n",
    "        aux = np.zeros((N,k+1))\n",
    "        aux2 = np.zeros((N,k+1))\n",
    "        aux3 = Y_sort[:,n-k-1:] # shape (N,k+1)\n",
    "        aux3_sum = np.sum(aux3,axis=1)\n",
    "        for i in numba.prange(k):\n",
    "            y_array[:,0,i] = Y_sort[:,n-i-1]\n",
    "            for j_2 in numba.prange(N):\n",
    "                y_array[j_2,:,i] = y_array[j_2,0,i]\n",
    "            hat_beta = fepls_numba(X,Y,y_array[:,:,i],tau) \n",
    "            for j_1 in numba.prange(N):\n",
    "                i_c = Y_sort_index[j_1,i]\n",
    "                aux[j_1,i]=(1/d)*np.sum(np.multiply(hat_beta[j_1,:],X[j_1,i_c,:]))\n",
    "                aux2[j_1,i]= np.multiply(aux[j_1,i],Y_sort[j_1,n-i-1]) \n",
    "                out[j_1,k]= np.corrcoef(aux3[j_1,:],aux[j_1,:])[0,1]\n",
    "    return out\n",
    "    \n",
    "def bitcoin_concomittant_corr(X,Y,tau,m): # 1\\le m \\le n \n",
    "    N = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    d = X.shape[2]\n",
    "    out = np.zeros((m))\n",
    "    Y_sort=np.sort(Y,axis=1)\n",
    "    Y_sort_index = np.argsort(Y,axis=1)\n",
    "    for k in range(m):\n",
    "        y_array = np.zeros((N,n,k+1))\n",
    "        aux = np.zeros((k+1))\n",
    "        aux2 = np.zeros((k+1))\n",
    "        aux3 = Y_sort[0,n-k-1:] # shape (k+1)\n",
    "        aux3_sum = np.sum(aux3)\n",
    "        for i in range(k):\n",
    "            y_array[:,:,i] = (Y_sort[0,n-i-1])*np.ones((1,n))\n",
    "            hat_beta = fepls(X,Y,y_array[:,:,i],tau) \n",
    "            i_c = Y_sort_index[0,i]\n",
    "            aux[i]=(1/d)*np.sum(np.multiply(hat_beta[0,:],X[0,i_c,:]))\n",
    "            aux2[i]= np.multiply(aux[i],Y_sort[0,n-i-1]) \n",
    "            out[k]= np.corrcoef(aux3,aux)[0,1]\n",
    "    return np.abs(out)\n",
    "\n",
    "def bitcoin_threshold_index(X,Y,tau,m,start): # 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    out = np.zeros((N,n))\n",
    "    return start+np.argmax(bitcoin_concomittant_corr(X,Y,tau,int(n/5))[start:])\n",
    "    \n",
    "def bitcoin_threshold(X,Y,tau,m,start):# 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    out = np.zeros((N,n))\n",
    "    Y_sort_index = np.argsort(Y,axis=1)\n",
    "    Y_sort=np.sort(Y,axis=1)\n",
    "    index = bitcoin_threshold_index(X,Y,tau,m,start)\n",
    "    out[0,:] = Y_sort[0,n-index-1]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def hatbeta_dot_X(X,hat_beta): # hat_beta=fepls(X,Y,y_matrix,tau) of shape (N,d)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    out=np.zeros((N,n))\n",
    "    for i in numba.prange(n):\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(hat_beta,X[:,i,:]),axis=1) \n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) # the same as np.dot(X,beta_func(d))/d (which is preferable)\n",
    "def beta_dot_X(X):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    out=np.zeros((N,n))\n",
    "    for i in numba.prange(n):\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func(d)),axis=1) \n",
    "    return out\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) # np.dot(X,beta_func(d))/d\n",
    "def beta_dot_X(X,beta_param):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    out=np.zeros((N,n))\n",
    "    for i in numba.prange(n):\n",
    "        if beta_param == 1:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func(d)),axis=1)\n",
    "        elif beta_param == 2:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func2(d)),axis=1)\n",
    "        elif beta_param == 3:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func3(d)),axis=1)\n",
    "        elif beta_param == 4:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func4(d)),axis=1)\n",
    "    return out\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def conditional_cov_Y_hat_beta_X(X,Y,hat_beta,y_matrix,tau): #hat_beta = fepls(X,Y,y_matrix,tau)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    A=hatbeta_dot_X(X,hat_beta)\n",
    "    cov_A=np.zeros((N,))\n",
    "    cov_B=np.zeros((N,))\n",
    "    for k in numba.prange(N):\n",
    "        cov_A[k] = (((A[k,:])[Y[k,:]>y_matrix[k,:]])*((Y[k,:])[Y[k,:]>y_matrix[k,:]])).mean() - ((A[k,:])[Y[k,:]>y_matrix[k,:]]).mean()*((Y[k,:])[Y[k,:]>y_matrix[k,:]]).mean()\n",
    "    return cov_A\n",
    "\n",
    "#@numba.njit(parallel=True, fastmath=False) # does not work with numba (no idea why)\n",
    "def conditional_cov_Y_beta_X(X,Y,y):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    B=beta_dot_X(X)\n",
    "    cov_B=np.zeros((N,))\n",
    "    for k in numba.prange(N):\n",
    "        cov_B[k] = (((B[k,:])[Y[k,:]>y])*((Y[k,:])[Y[k,:]>y])).mean()-((B[k,:])[Y[k,:]>y]).mean()*((Y[k,:])[Y[k,:]>y]).mean()\n",
    "    return cov_B\n",
    "\n",
    "def Exponential_QQ_Plot_1D(Y,k):\n",
    "    n=Y.shape[1]\n",
    "    out=np.zeros((k))\n",
    "    out2=np.zeros((k))\n",
    "    YY=np.sort(Y,axis=1)\n",
    "    for i in range(k):\n",
    "        out[i]=np.log((k+1)/(i+1))\n",
    "        out2[i]=  np.log(YY[0,n-i-1])-np.log(YY[0,-k])\n",
    "    return np.column_stack((out,out2))\n",
    "\n",
    "################################################## Conditional quantile estimation (2D+3D array)\n",
    "################# Application: Bitcoin/SP500 quantile\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def Epanechnikov_kernel_2D(x): # x is a np.array of shape (p,q);     W=np.where(np.abs(x)<=1,1,0)\n",
    "    out = np.zeros_like(x)\n",
    "    x=np.asarray(x)\n",
    "    for i in numba.prange(x.shape[0]):\n",
    "        for j in numba.prange(x.shape[1]):\n",
    "            if x[i,j]<=1 and x[i,j]>=0:\n",
    "                out[i,j] = np.multiply(3/2,1-np.power(x[i,j],2))\n",
    "            else:\n",
    "                out[i,j]=0\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def Epanechnikov_kernel_1D(x): # x is a np.array of shape (p);     W=np.where(np.abs(x)<=1,1,0)\n",
    "    out = np.zeros_like(x)\n",
    "    x=np.asarray(x)\n",
    "    for i in numba.prange(x.shape[0]):\n",
    "        if x[i]<=1 and x[i]>=0:\n",
    "            out[i] = np.multiply(3/2,1-np.power(x[i],2))\n",
    "        else:\n",
    "            out[i]=0\n",
    "    return out\n",
    "    \n",
    "@numba.njit(parallel=False, fastmath=False) \n",
    "def Gaussian_kernel(x):\n",
    "    return (1/np.sqrt(2*np.pi))*np.exp(-0.5*np.power(x,2))\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def univariate_Nadaraya_weight(X_dimred,x,h,kernel): # X_dimred of shape (N,n) just as Y \n",
    "    # e.g., X_dimred = hatbeta_dot_X(X,hat_beta) = F0\n",
    "    # hat_beta=fepls(X,Y,y_matrix,tau)=E0; x real and h positive\n",
    "    N=X_dimred.shape[0]\n",
    "    n=X_dimred.shape[1]\n",
    "    out=np.zeros((N,n))\n",
    "    if kernel == 1:\n",
    "        K_h=Epanechnikov_kernel_2D((X_dimred-x)/h) # shape (N,n)\n",
    "    if kernel == 2:\n",
    "        K_h=Gaussian_kernel((X_dimred-x)/h) # shape (N,n)\n",
    "    return K_h/np.sum(K_h) ### shape = (N,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_test_2D(X,Y,X_dimred,inner_prod,x_func,alpha,a,b,m,h,h_func,kernel): # X_dimred.shape = Y.shape = (N,n), e.g., X_dimred = hatbeta_dot_X(X,hat_beta) = F0\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]; h_func is positive\n",
    "    # x_func_dot_beta.shape in \\R; it represents the inner product between x_func (where we project for the plot) and the vector in H reducing the dimension\n",
    "    # inner_prod.shape \\in\\R represents (x_func,beta)\n",
    "    #  beta is reducing the dimension, i.e., X_dimred=(X,beta).\n",
    "    # X_dimred = (X,beta); Y|X_dimred = x vs Y|X=x*x_func  \n",
    "    out = np.zeros((m,2))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func,kernel) \n",
    "        weight1=univariate_Nadaraya_weight(X_dimred,x_grid[p]*inner_prod,h,kernel)[0,:]  \n",
    "        out[p,0]=weighted_quantile(Y[0,:],weight1,alpha)\n",
    "        out[p,1]=weighted_quantile(Y[0,:],weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def univariate_Nadaraya_weight_2D(X_2D,dimred,x_func,x,h,type,kernel): # X of shape (n,d), Y of shape (n), dimred and x_func of shape (d,)\n",
    "    # dimred of shape (d,) is e.g. beta_func(d) or (fepls(X,Y,y_matrix,tau))[0,:]\n",
    "    # Y|(X,dimred)=(x_func,dimred) (type 1) vs Y|(X,dimred) = x (type 2)\n",
    "    d=x_func.shape[0]\n",
    "    if type == 1:\n",
    "        if kernel == 1:\n",
    "            K_h=Epanechnikov_kernel_1D((np.dot(X_2D,dimred)/d-np.dot(x_func,dimred)/d)/h) # shape (n,)\n",
    "        if kernel == 2:\n",
    "            K_h=Gaussian_kernel((np.dot(X_2D,dimred)/d-np.dot(x_func,dimred)/d)/h) # shape (n,)\n",
    "    if type == 2:     \n",
    "        if kernel == 1:\n",
    "            K_h=Epanechnikov_kernel_1D((np.dot(X_2D,dimred)/d-x)/h) # shape (n,)\n",
    "        if kernel == 2:\n",
    "            K_h=Gaussian_kernel((np.dot(X_2D,dimred)/d-x)/h) # shape (n,)\n",
    "    return K_h/np.sum(K_h) ### shape = (,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def functional_Nadaraya_weight_2D(X_2D,x_func,h,kernel): # X.shape = (n,d); h is positive ; x_func \\in H ie of shape (d,)\n",
    "    d=x_func.shape[0]\n",
    "    aux = (X_2D-x_func*np.ones(d))**2 # shape = (n,d)\n",
    "    norm = np.sqrt((1/d)*np.sum(aux,axis=1)) # shape = (n,)\n",
    "    if kernel == 1:\n",
    "        K_h= Epanechnikov_kernel_1D(norm/h) # shape = (n,)\n",
    "    if kernel == 2:\n",
    "        K_h= Gaussian_kernel(norm/h)## shape = (n,)\n",
    "    return K_h/np.sum(K_h) ### shape = (n,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def univariate_Nadaraya_weight_3D(X,dimred_2D,x_func,x,h,type,kernel): # X of shape (N,n,d), Y of shape (N,n), dimred_2D of shape (N,d)\n",
    "    # x_func of shape (d,) is e.g. beta_func(d) or (fepls(X,Y,y_matrix,tau))[0,:]\n",
    "    # x is a real number (e.g., x=x_grid[p] for p \\leq m)\n",
    "    # Y|(X,dimred)=(x_func,dimred) (type 1) vs Y|(X,dimred) = x (type 2)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    K_h = np.zeros((N,n))\n",
    "    for i in numba.prange(N):\n",
    "        if type == 1:\n",
    "            if kernel == 1:\n",
    "                K_h[i,:]=Epanechnikov_kernel_1D((np.dot(X[i,:,:],dimred_2D[i,:])/d-np.dot(x_func,dimred_2D[i,:])/d)/h) # shape (n,)\n",
    "            if kernel == 2:\n",
    "                K_h[i,:]=Gaussian_kernel((np.dot(X[i,:,:],dimred_2D[i,:])/d-np.dot(x_func,dimred_2D[i,:])/d)/h) # shape (n,)\n",
    "        if type == 2:\n",
    "            if kernel == 1:\n",
    "                K_h[i,:]=Epanechnikov_kernel_1D((np.dot(X[i,:,:],dimred_2D[i,:])/d-x)/h) # shape (n,)   \n",
    "            if kernel == 2:\n",
    "                K_h[i,:]=Gaussian_kernel((np.dot(X[i,:,:],dimred_2D[i,:])/d-x)/h) # shape (n,)\n",
    "    return np.transpose(np.transpose(K_h)/np.sum(K_h,axis=1)) ### shape = (N,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def functional_Nadaraya_weight_3D(X,x_func,h_func_2D,kernel): # X.shape = (N,n,d); h_func_2D.shape = (N,n); x_func \\in H ie of shape (d,)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    aux = np.zeros((N,n,d))\n",
    "    for i in numba.prange(N):\n",
    "        aux[i,:,:] = (X[i,:,:]-x_func*np.ones(d))**2\n",
    "    norm = np.sqrt((1/d)*np.sum(aux,axis=2))\n",
    "    if kernel == 1:\n",
    "        K_h= Epanechnikov_kernel_2D(norm/h_func_2D)\n",
    "    if kernel == 2:\n",
    "        K_h= Gaussian_kernel(norm/h_func_2D)      \n",
    "    return np.transpose(np.transpose(K_h)/np.sum(K_h,axis=1)) ### shape = (N,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)   \n",
    "def weighted_quantile(data,weight,alpha):  # data.shape=weight.shape=(n,) \n",
    "    # alpha is the treshold in (0,1)\n",
    "    sorter = np.argsort(data)\n",
    "    data = data[sorter]\n",
    "    weight = weight[sorter]\n",
    "    weighted_quantiles = np.cumsum(weight) - 0.5 * weight\n",
    "    weighted_quantiles /= np.sum(weight)\n",
    "    return np.interp(alpha, weighted_quantiles, data)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def iterated_weq_2D(data_2D,weight,alpha): # same treshold for all marginals and iterations \n",
    "    # data.shape = (N,n); weight.shape=(N,n)\n",
    "    N=data_2D.shape[0]\n",
    "    n=data_2D.shape[1]\n",
    "    out = np.zeros((N,))\n",
    "    for k in numba.prange(N):\n",
    "        out[k]=weighted_quantile(data_2D[k,:],weight[k,:],alpha)\n",
    "    return out # shape = (N)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_dimred_vs_func_2D(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h,h_func,kernel): # dimred1,2 and x_func of shape (d,), e.g., dimred = E0[0,:] with E0 = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    out = np.zeros((m,3))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        #weight_func=functional_Nadaraya_weight(X,x_grid[p]*x_func,h)[0,:]#functional_Nadaraya_weight_Bitcoin(X,x_grid[p]*x_func,h)\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func,kernel)\n",
    "        weight1=univariate_Nadaraya_weight_2D(X[0,:,:],dimred1,x_grid[p]*x_func,x_grid[p],h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_2D(X[0,:,:],dimred2,x_grid[p]*x_func,x_grid[p],h,2,kernel)\n",
    "        out[p,0]=weighted_quantile(Y[0,:],weight1,alpha)\n",
    "        out[p,1]=weighted_quantile(Y[0,:],weight2,alpha)\n",
    "        out[p,2]=weighted_quantile(Y[0,:],weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_dimred_vs_func_2D_total(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h_vector,h_func_vector,kernel): # dimred1,2 and x_func of shape (d,), e.g., dimred = E0[0,:] with E0 = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "    # h_vector.shape = h_func_vector.shape = (m,)\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    out = np.zeros((m,3))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        #weight_func=functional_Nadaraya_weight(X,x_grid[p]*x_func,h)[0,:]#functional_Nadaraya_weight_Bitcoin(X,x_grid[p]*x_func,h)\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func_vector[p],kernel)\n",
    "        weight1=univariate_Nadaraya_weight_2D(X[0,:,:],dimred1,x_grid[p]*x_func,x_grid[p],h_vector[p],1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_2D(X[0,:,:],dimred2,x_grid[p]*x_func,x_grid[p],h_vector[p],2,kernel)\n",
    "        out[p,0]=weighted_quantile(Y[0,:],weight1,alpha)\n",
    "        out[p,1]=weighted_quantile(Y[0,:],weight2,alpha)\n",
    "        out[p,2]=weighted_quantile(Y[0,:],weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def plot_quantile_covariate_dimred_vs_func_3D(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h,h_func_2D,kernel): # dimred1,2 of shape (N,d), e.g., dimred = E = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "    # h_func_2D.shape = (N,n)\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    N=X.shape[0]\n",
    "    out = np.zeros((N,m,3))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        weight_func=functional_Nadaraya_weight_3D(X,x_grid[p]*x_func,h_func_2D,kernel)\n",
    "        weight1=univariate_Nadaraya_weight_3D(X,dimred1,x_grid[p]*x_func,x_grid[p],h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_3D(X,dimred2,x_grid[p]*x_func,x_grid[p],h,2,kernel)\n",
    "        out[:,p,0]=iterated_weq_2D(Y,weight1,alpha)\n",
    "        out[:,p,1]=iterated_weq_2D(Y,weight2,alpha)\n",
    "        out[:,p,2]=iterated_weq_2D(Y,weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_alpha_dimred_vs_func_3D(X,Y,dimred1,dimred2,x_func,x,a,b,m,h,h_func,type,kernel): # dimred of shape (N,d), e.g., dimred = E = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    N=X.shape[0]\n",
    "    out = np.zeros((N,m,3))\n",
    "    alpha_grid = np.linspace(0,1,m)\n",
    "    for p in range(m):\n",
    "        weight_func=functional_Nadaraya_weight_3D(X,x_func,h_func,kernel)\n",
    "        weight1=univariate_Nadaraya_weight_3D(X,dimred1,x_func,x,h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_3D(X,dimred2,x_func,x,h,2,kernel)\n",
    "        out[:,p,0]=iterated_weq_2D(Y,weight1,alpha_grid[p])\n",
    "        out[:,p,1]=iterated_weq_2D(Y,weight1,alpha_grid[p])\n",
    "        out[:,p,2]=iterated_weq_2D(Y,weight_func,alpha_grid[p])\n",
    "    return out\n",
    "\n",
    "################################################## ][ Tail index  \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def get_hill_estimator(ordered_data):\n",
    "    \"\"\"\n",
    "    Function to calculate Hill estimator array given an ordered data\n",
    "    sequence. Decreasing ordering is required; e.g. ordered_data = np.sort(data[0,:])[::-1] where data might be Y (of shape (N,n))\n",
    "    :param ordered_data: numpy array of ordered data for which the 1st moment (Hill estimator) is calculated.\n",
    "    :return: numpy array of Hill estimator corresponding to all possible order statistics of the dataset.\n",
    "    \"\"\"\n",
    "    logs = np.log(ordered_data)\n",
    "    logs_cumsum = np.cumsum(logs[:-1])\n",
    "    k_vector = np.arange(1, len(ordered_data))\n",
    "    m1 = (1./k_vector)*logs_cumsum - logs[1:]\n",
    "    return m1\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def get_hill_estimator_2D(ordered_data_2D): # ordered_data_2D = np.sort(-data,axis=1)*-1 with data 2D-array\n",
    "    \"\"\"\n",
    "    Function to calculate Hill estimator array given an ordered data; e.g., ordered_data_2D = np.sort(-Y,axis=1)*-1\n",
    "    sequence. Decreasing ordering is required; e.g. ordered_data = np.sort(data[0,:])[::-1] where data might be Y (of shape (N,n))\n",
    "    :param ordered_data: numpy array of ordered data for which the 1st moment (Hill estimator) is calculated.\n",
    "    :return: numpy array of Hill estimator corresponding to all possible order statistics of the dataset.\n",
    "    \"\"\"\n",
    "    N=ordered_data_2D.shape[0]\n",
    "    n=ordered_data_2D.shape[1]\n",
    "    m1=np.zeros((N,n-1))\n",
    "    for i in numba.prange(N):\n",
    "        logs = np.log(ordered_data_2D[i,:]) \n",
    "        logs_cumsum = np.cumsum(logs[:-1])\n",
    "        k_vector = np.arange(1, len(ordered_data_2D[i,:]))\n",
    "        m1[i,:] = (1./k_vector)*logs_cumsum - logs[1:]\n",
    "    return m1\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def Hill_estimator_one_value(ordered_data, k):\n",
    "    \"\"\"\n",
    "    Function to calculate the Hill estimator for a specified order statistic k. Decreasing ordering is required.\n",
    "    :param ordered_data: Decreasingly ordered sample; e.g. ordered_data = np.sort(data[0,:])[::-1] where data might be Y (of shape (N,n))\n",
    "    :param k: from 1 up to and including len(ordered_data) - 1\n",
    "    :return: float with the value of the Hill estimator\n",
    "    \"\"\"\n",
    "    selected_logs = np.log(ordered_data[:k+1])\n",
    "    return 1./k * sum(selected_logs[:-1]) - selected_logs[-1]\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def Hill_estimator_one_value_2D(ordered_data_2D, k): # ordered_data_2D = np.sort(-data,axis=1)*-1 with data 2D-array\n",
    "    N=ordered_data_2D.shape[0]\n",
    "    n=ordered_data_2D.shape[1]\n",
    "    out=np.zeros((N,))\n",
    "    for i in numba.prange(N):\n",
    "        selected_logs = np.log(ordered_data_2D[i,:k+1])\n",
    "        out[i]=1./k * sum(selected_logs[:-1]) - selected_logs[-1]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def tail_index_gamma_estimator(data,weight,alpha,J): \n",
    "    N=data.shape[0]\n",
    "    d=data.shape[2]\n",
    "    subdivision=np.array([(1/s) for s in np.arange(1,J+1)] )\n",
    "    quantile_data2=iterated_weq(data,weight,alpha) # quantile_data2.shape=(N,d)\n",
    "    out=np.zeros((N,))\n",
    "    aux=np.zeros((N,J))\n",
    "    for k in numba.prange(N):\n",
    "        for j in numba.prange(J):\n",
    "            quantile_data1=iterated_weq(data,weight,1-subdivision[j]*(1-alpha))\n",
    "            aux[k,j] = np.log(quantile_data1[k,0])-np.log(quantile_data2[k,0])\n",
    "            aux[k,j] /= -np.sum(np.log(subdivision))\n",
    "        out[k] = np.sum(aux[k,:])\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def tail_index_gamma_estimator_2D(Y,weight,alpha,J):  # Y.shape= (N,n); weight.shape = (n,)\n",
    "    subdivision=np.array([(1/s) for s in np.arange(1,J+1)] )\n",
    "    quantile_data2=weighted_quantile(Y[0,:],weight,alpha) # \n",
    "    aux=np.zeros((J))\n",
    "    for j in numba.prange(J):\n",
    "        quantile_data1=weighted_quantile(Y[0,:],weight,1-subdivision[j]*(1-alpha))\n",
    "        aux[j] = np.log(quantile_data1)-np.log(quantile_data2)\n",
    "        aux[j] /= -np.sum(np.log(subdivision))\n",
    "    return np.sum(aux)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False)  \n",
    "def plot_tail_index_all_2D(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h,h_func,J,kernel): # Y.shape = (N,n); X.shape = (N,n,d); Y.shape = (n); x_func.shape = (d,); J=9\n",
    "    # dimred1.shape = dimred2.shape = (d,)\n",
    "    # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    x_grid=np.linspace(a,b,m)\n",
    "    out=np.zeros((m,3))\n",
    "    for p in numba.prange(m):\n",
    "        weight1=univariate_Nadaraya_weight_2D(X[0,:,:],dimred1,x_grid[p]*x_func,x_grid[p],h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_2D(X[0,:,:],dimred2,x_grid[p]*x_func,x_grid[p],h,2,kernel)\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func,kernel)\n",
    "        out[p,0]=tail_index_gamma_estimator_2D(Y,weight1,alpha,J)\n",
    "        out[p,1]=tail_index_gamma_estimator_2D(Y,weight2,alpha,J)\n",
    "        out[p,2]=tail_index_gamma_estimator_2D(Y,weight_func,alpha,J)\n",
    "    return out\n",
    "\n",
    "################################################## ][ Copula \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def marginal_wecdf(data,weight,x_vect): # x row vector of length d (each marginal has its own treshold)\n",
    "    # e.g. for uniform treshold t, x_vect=x*np.ones((d,))\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n)\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    out=np.zeros((N,d))\n",
    "    for k in numba.prange(N):\n",
    "        for j in numba.prange(d):\n",
    "            indicator_matrix = np.where(data[:,:,j]<x_vect[j],1,0) # binary matrix with same shape as data representating the indicator matrix 1_{X_ij<x_j}\n",
    "            out[k,j]= np.sum(np.multiply(indicator_matrix[k,:],weight[k,:]))\n",
    "    return out/n # (N,d)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def rank(U): # U.shape = (N,n,d)\n",
    "    R = np.empty_like(U)\n",
    "    for p in numba.prange(U.shape[0]):\n",
    "        for j in numba.prange(U.shape[2]):\n",
    "            R[p,:, j] = np.argsort(np.argsort(U[p,:, j]))+1\n",
    "    return R\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def weighted_ranked_data(R,weight): # ie: \\hat{F}_{j,n,y}(X_ij); R = rank(data) with shape (N,n,d); weight.shape=(N,n)\n",
    "    N=R.shape[0]\n",
    "    n=R.shape[1]\n",
    "    d=R.shape[2]\n",
    "    out=np.zeros((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            for j in numba.prange(d):\n",
    "                r=np.int32(R[k,i,j])\n",
    "                out[k,i,j]=np.sum(weight[k,0:r])\n",
    "    return out/n \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_indicator(data,j,k,x,y): # data.shape = (N,n,d); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    A=np.where(data[:,:,j]<x,1,0)\n",
    "    B=np.where(data[:,:,k]<y,1,0)\n",
    "    return np.multiply(A,B) # shape = (N,n)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_anti_indicator(data,j,k,x,y): # data.shape = (N,n,d); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    A=np.where(data[:,:,j]<x,0,1)\n",
    "    B=np.where(data[:,:,k]<y,0,1)\n",
    "    return np.multiply(A,B) # shape = (N,n)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_wecdf(data,weight,j_1,j_2,x,y):\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    biv_indicator=bivariate_indicator(data,j_1,j_2,x,y)\n",
    "    return np.sum(np.multiply(biv_indicator,weight),axis=1)/n # shape = (N,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_ecdf(data,j_1,j_2,x,y):\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    biv_indicator=bivariate_indicator(data,j_1,j_2,x,y)\n",
    "    return np.sum((biv_indicator),axis=1)/n # shape = (N,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_survival_wecdf(data,weight,j_1,j_2,x,y):\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    biv_indicator=bivariate_anti_indicator(data,j_1,j_2,x,y)\n",
    "    return np.sum(np.multiply(biv_indicator,weight),axis=1)/n # shape = (N,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def empirical_uniform_data(data,weight): \n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    out = np.zeros((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            out[k,i,:]=marginal_wecdf(data,weight,data[k,i,:])[k,:]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def weighted_empirical_copula(data,weight,j_1,j_2,u,v): # u.shape = (2,) in (0,1)\n",
    "        # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j_1\\neq j_2 \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    out=np.zeros((N,n))\n",
    "    data=empirical_uniform_data(data,weight)\n",
    "    biv_indicator=bivariate_indicator(emp_unif_data,j_1,j_2,u,v)\n",
    "    out= np.multiply(biv_indicator,weight)/n \n",
    "    return np.sum(out,axis=1) # return (N)-shape\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def weighted_ranked_empirical_copula(weighted_ranked_data,weight,j_1,j_2,u,v): # u,v in (0,1)\n",
    "        # weighted_ranked_data=weighted_ranked_data(R.astype(int),weight) where R=rank(data); \n",
    "        # weighted_ranked_data.shape = (N,n,d) is ; weight.shape=(N,n); 1\\le j_1\\neq j_2 \\le d\n",
    "    N=weighted_ranked_data.shape[0]\n",
    "    n=weighted_ranked_data.shape[1]\n",
    "    d=weighted_ranked_data.shape[2]\n",
    "    out=np.zeros((N,n))\n",
    "    biv_indicator=bivariate_indicator(weighted_ranked_data,j_1,j_2,u,v)\n",
    "    out= np.multiply(biv_indicator,weight)/n \n",
    "    return np.sum(out,axis=1) # return (N)-shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################## Execute (Synthetic Data)\n",
    "\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 1 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Y_sim=Y\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold(X,Y,Y_sort_index,tau,100,start)\n",
    "E = fepls(X,Y,y_matrix,tau)\n",
    "#E2 = fepls_numba(X,Y,y_matrix,tau) # Same but not parallelizable and slower...\n",
    "#F=hatbeta_dot_X(X,E)\n",
    "\n",
    "#############################################################################\n",
    "print(check_cond_no_q(gamma,c,tau))\n",
    "print(\"Time cost\",time.time()-tic)\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################## Plot Histograms (Synthetic Data)\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=9/10# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "plt.hist(y_matrix, bins=m)\n",
    "plt.savefig('hist_k_10_2_0_9.pdf')  \n",
    "plt.show()\n",
    "\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "gamma=1/2\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "plt.hist(y_matrix, bins=m)\n",
    "plt.savefig('hist_k_10_2_0_5.pdf')  \n",
    "plt.show()\n",
    "\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "gamma=1/3\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "plt.hist(y_matrix, bins=m)\n",
    "plt.savefig('hist_k_10_2_0_333.pdf')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################ Estim plot (Synthetic Data)\n",
    "\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 3/2 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "start=4\n",
    "l=2 # grid parameter\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix2 = threshold(X,Y,Y_sort_index,tau,100,0)\n",
    "y_matrix3 = threshold(X,Y,Y_sort_index,tau,100,4)\n",
    "y_matrix4 = threshold(X,Y,Y_sort_index,tau,100,9)\n",
    "\n",
    "E2 = fepls(X,Y,y_matrix2,tau)\n",
    "E3 = fepls(X,Y,y_matrix3,tau)\n",
    "E4 = fepls(X,Y,y_matrix4,tau)\n",
    "\n",
    "#############################################################################\n",
    "print(check_cond_no_q(gamma,c,tau))\n",
    "##################################################################################################\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "#max_values = np.max(E, axis=0) # shape (d,)\n",
    "#min_values = np.min(E, axis=0) # shape (d,)\n",
    "max_values2 = np.nanquantile(E2, 0.95, axis=0) # shape (d,)\n",
    "min_values2 = np.nanquantile(E2, 0.05, axis=0) # shape (d,)\n",
    "mean_values2 = np.nanmean(E2, axis=0) # shape (d,)\n",
    "median_values2 = np.nanmedian(E2, axis=0) # shape (d,)\n",
    "\n",
    "# Create x values (assuming x values are just indices in this case)\n",
    "x_values = np.arange(d)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [0,1]\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "ax.set_xticklabels([0,0 , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 ])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "ax.fill_between(x_values, min_values2, max_values2, color='skyblue', alpha=0.4)\n",
    "ax.plot(x_values, mean_values2)\n",
    "ax.plot(x_values, beta_func(d))\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "#plt.legend()\n",
    "# Show the plot\n",
    "plt.savefig('beta_estim_plot_conc100_0_1_5_0_333.pdf')  \n",
    "plt.show()\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "#max_values = np.max(E, axis=0) # shape (d,)\n",
    "#min_values = np.min(E, axis=0) # shape (d,)\n",
    "max_values3 = np.nanquantile(E3, 0.95, axis=0) # shape (d,)\n",
    "min_values3 = np.nanquantile(E3, 0.05, axis=0) # shape (d,)\n",
    "mean_values3 = np.nanmean(E3, axis=0) # shape (d,)\n",
    "median_values3 = np.nanmedian(E3, axis=0) # shape (d,)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [0,1]\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "ax.set_xticklabels([0,0 , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 ])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "ax.fill_between(x_values, min_values3, max_values3, color='skyblue', alpha=0.4)\n",
    "ax.plot(x_values, mean_values3)\n",
    "ax.plot(x_values, beta_func(d))\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "#plt.legend()\n",
    "# Show the plot\n",
    "plt.savefig('beta_estim_plot_conc100_4_1_5_0_333.pdf')  \n",
    "plt.show()\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "#max_values = np.max(E4, axis=0) # shape (d,)\n",
    "#min_values = np.min(E4, axis=0) # shape (d,)\n",
    "max_values4 = np.nanquantile(E4, 0.95, axis=0) # shape (d,)\n",
    "min_values4 = np.nanquantile(E4, 0.05, axis=0) # shape (d,)\n",
    "mean_values4 = np.nanmean(E4, axis=0) # shape (d,)\n",
    "median_values4 = np.nanmedian(E4, axis=0) # shape (d,)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [0,1]\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "ax.set_xticklabels([0,0 , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 ])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "ax.fill_between(x_values, min_values4, max_values4, color='skyblue', alpha=0.4)\n",
    "ax.plot(x_values, mean_values4)\n",
    "ax.plot(x_values, beta_func(d))\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "#plt.legend()\n",
    "# Show the plot\n",
    "plt.savefig('beta_estim_plot_conc100_9_1_5_0_333.pdf')  \n",
    "plt.show()\n",
    "\n",
    "print(\"Time cost\",time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time cost 25580.601355075836\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################### Hyperparameters and Sample\n",
    "\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Y_sim=Y\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "\n",
    "\n",
    "#################################################### Correlation (concomittant) plot (Synthetic data)\n",
    "\n",
    "m=int(n/2) # 1\\le m \\le n\n",
    "tic=time.time()\n",
    "A=concomittant_corr(X,Y,Y_sort_index,-1,m)[:,1:]\n",
    "A2=concomittant_corr(X,Y,Y_sort_index,-2,m)[:,1:]\n",
    "A3=concomittant_corr(X,Y,Y_sort_index,-3,m)[:,1:]\n",
    "print(\"Time cost\",time.time()-tic)\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "\n",
    "mean_values_A = np.nanmean(A, axis=0) # shape (int(n/l),)\n",
    "#median_values_A = np.nanmedian(A, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A2 = np.nanmean(A2, axis=0) # shape (int(n/l),)\n",
    "#median_values_A2 = np.nanmedian(A2, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A3 = np.nanmean(A3, axis=0) # shape (int(n/l),)\n",
    "#median_values_A3 = np.nanmedian(A3, axis=0) # shape (int(n/l),)\n",
    "\n",
    "# Create x values (assuming x values are just indices in this case)\n",
    "x_values_A = np.arange(m-1)#np.arange(int(n/l))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [1,250]\n",
    "#ax.xaxis.set_major_locator(plt.MaxNLocator(27))\n",
    "#ax.set_xticklabels([1, 1, 10 , 20, 30,  40, 50, 60, 70, 80, 90, 100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "#ax.fill_between(x_values_A, min_values_A, max_values_A, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A, label='tau = -1')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A2, max_values_A2, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A2, label='tau = -2')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A3, max_values_A3, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A3, label='tau = -3')\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "plt.legend()\n",
    "plt.savefig('beta_estim_corr_2_0_333.pdf')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### Hyperparameters and Sample\n",
    "\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 1 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Y_sim=Y\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "\n",
    "####################################################### hatbeta_dot_beta (Synthetic Data)\n",
    "\n",
    "l=2 # grid parameter\n",
    "A=hatbeta_dot_beta(X,Y,-1,l)\n",
    "A2=hatbeta_dot_beta(X,Y,-2,l)\n",
    "A3=hatbeta_dot_beta(X,Y,-3,l)\n",
    "\n",
    "print(\"Time cost\",time.time()-tic)\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "mean_values_A = np.nanmean(A, axis=0) # shape (int(n/l),)\n",
    "#median_values_A = np.nanmedian(A, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A2 = np.nanmean(A2, axis=0) # shape (int(n/l),)\n",
    "#median_values_A2 = np.nanmedian(A2, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A3 = np.nanmean(A3, axis=0) # shape (int(n/l),)\n",
    "#median_values_A3 = np.nanmedian(A3, axis=0) # shape (int(n/l),)\n",
    "\n",
    "# Create x values (assuming x values are just indices in this case)\n",
    "x_values_A = np.arange(int(n/l))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "#ax.fill_between(x_values_A, min_values_A, max_values_A, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A, label='tau = -2')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A2, max_values_A2, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A2, label='tau = -3')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A3, max_values_A3, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A3, label='tau = -4')\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "plt.legend()\n",
    "#plt.savefig('beta_estim_exceedance_1_5_0_9.pdf')\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
