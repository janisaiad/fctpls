{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_boUx_3FvO4O"
   },
   "outputs": [],
   "source": [
    "###################### Magic commands\n",
    "\n",
    "##%%timeit -n 1 -r 1\n",
    "#%%time\n",
    "import time\n",
    "#start = time.time()\n",
    "\n",
    "###################### at the end\n",
    "\n",
    "#end = time.time()\n",
    "#print(end - start)\n",
    "\n",
    "###################### Packages\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as npr\n",
    "import pandas as pd\n",
    "#import Pyarrow # for pandas\n",
    "import scipy.special\n",
    "import math \n",
    "import numba\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "from fctpls.utils import stooq_txt_to_df, stooq_to_notebook_format\n",
    "\n",
    "# we load stooq data (with\n",
    "# pip install fbm\n",
    "# from fbm import FBM\n",
    "\n",
    "###################### Options\n",
    "\n",
    "npr.seed(0)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#<\n",
    "#>\n",
    "\n",
    "############### Tools transfering numpy to numba\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def np_apply_along_axis_2darray(func1d, axis, arr):\n",
    "  assert arr.ndim == 2\n",
    "  assert axis in [0, 1]\n",
    "  if axis == 0:\n",
    "    result = np.empty(arr.shape[1])\n",
    "    for i in numba.prange(len(result)):\n",
    "      result[i] = func1d(arr[:, i])\n",
    "  else:\n",
    "    result = np.empty(arr.shape[0])\n",
    "    for i in numba.prange(len(result)):\n",
    "      result[i] = func1d(arr[i, :])\n",
    "  return result\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def np_mean_2darray(array, axis):\n",
    "  return np_apply_along_axis_2darray(np.mean, axis, array)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def np_std_2darray(array, axis):\n",
    "  return np_apply_along_axis_2darray(np.std, axis, array)\n",
    "\n",
    "################################################## Non-empty\n",
    "\n",
    "def check_cond(gamma,c,tau,q):\n",
    "    if 0<tau:\n",
    "        if gamma<1 and 0<gamma and 2<q and 0<c and 2*(c+tau)*gamma<1 and q*(1-2*tau*gamma)>2 and q*c*gamma>1 and tau <1/(2*gamma):\n",
    "            print('Valid!')\n",
    "        else:\n",
    "            print('Not valid!')\n",
    "    else:\n",
    "        if gamma<1 and 0<gamma and 2<q and 0<c and 2*(c+tau)*gamma<1 and q*c*gamma>1:\n",
    "            print('Valid!')\n",
    "        else:\n",
    "            print('Not valid!')        \n",
    "    return\n",
    "\n",
    "def check_cond_no_q(gamma,c,tau):\n",
    "    if gamma<1 and 0<gamma and 0<c and 2*(c+tau)*gamma<1:\n",
    "        print('Valid!')\n",
    "    else:\n",
    "        print('Not valid!')   \n",
    "    return\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=True)\n",
    "def find_cond_all(h_gamma,h_c,h_tau,h_q,max_c,max_tau,max_q):\n",
    "    gamma_mesh = np.linspace(0.01,0.99,h_gamma)\n",
    "    c_mesh = np.linspace(0.1,max_c,h_c)\n",
    "    tau_mesh = np.linspace(-max_tau,max_tau,h_tau)\n",
    "    q_mesh = np.linspace(2.1,max_q,h_q)\n",
    "    for gamma_index in numba.prange(h_gamma):\n",
    "        for c_index in numba.prange(h_c): \n",
    "            for tau_index in numba.prange(h_tau):\n",
    "                for q_index in numba.prange(h_q):\n",
    "                    gamma=gamma_mesh[gamma_index]\n",
    "                    c=c_mesh[c_index]\n",
    "                    tau=tau_mesh[tau_index]\n",
    "                    q=q_mesh[q_index]\n",
    "                    if 0<tau:\n",
    "                        if 2<q and 0<c and 2*(c+tau)*gamma<1 and q*(1-2*tau*gamma)>2 and q*c*gamma>1:\n",
    "                            print([gamma, c, tau, q])\n",
    "                    else:\n",
    "                        if 2<q and 0<c and 2*(c+tau)*gamma<1 and q*c*gamma>1:\n",
    "                            print([gamma, c, tau, q])                        \n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_cond_no_q(grid_gamma,max_tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    c_mesh = np.arange(1,10)\n",
    "    tau_mesh = np.arange(-max_tau,max_tau+1)\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        for c_index in numba.prange(c_mesh.shape[0]): \n",
    "            for tau_index in numba.prange(tau_mesh.shape[0]):\n",
    "                gamma=gamma_mesh[gamma_index]\n",
    "                c=c_mesh[c_index]\n",
    "                tau=tau_mesh[tau_index]\n",
    "                if 2*(c+tau)*gamma<1:\n",
    "                    print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_gamma_no_q(grid_gamma,c,tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        gamma=gamma_mesh[gamma_index]\n",
    "        if 2*(c+tau)*gamma<1:\n",
    "            print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_cond_c_no_q(c,grid_gamma,max_tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    tau_mesh = np.arange(-max_tau,max_tau+1)\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        for tau_index in numba.prange(tau_mesh.shape[0]):\n",
    "            gamma=gamma_mesh[gamma_index]\n",
    "            tau=tau_mesh[tau_index]\n",
    "            if 2*(c+tau)*gamma<1:\n",
    "                print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def find_cond_c_tau_no_q(c,tau,grid_gamma,max_tau):\n",
    "    gamma_mesh = np.linspace(0,1,grid_gamma+1)[1:grid_gamma]\n",
    "    tau_mesh = np.arange(-max_tau,max_tau+1)\n",
    "    for gamma_index in numba.prange(gamma_mesh.shape[0]):\n",
    "        for tau_index in numba.prange(tau_mesh.shape[0]):\n",
    "            gamma=gamma_mesh[gamma_index]\n",
    "            tau=tau_mesh[tau_index]\n",
    "            if 2*(c+tau)*gamma<1:\n",
    "                print([gamma, c, tau])\n",
    "    return 'Done!'\n",
    "\n",
    "################################################## Generating Data\n",
    "\n",
    "@numba.njit(parallel=False, fastmath=False)\n",
    "def Lomax_quantile_function(x,theta,s):  \n",
    "    return s*((1-x)**(-1/theta)-1)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def Pareto_quantile_function(x,gamma,s): # support is  {x \\ge s} and theta=1/\\gamma\n",
    "    return s*(1-x)**(-gamma)\n",
    "\n",
    "#The Burr distribution has survival distribution $\\bar{F}(y)=(1+y^\\rho)^{-\\theta} \\in 2\\RV_{-\\theta \\rho,-\\rho}$ where $x\\ge 0$ and $\\theta,\\rho>0$.\n",
    "@numba.njit(parallel=True, fastmath=False) # rho,theta positive\n",
    "def Burr_quantile_function(x,theta,rho): \n",
    "    return ((1-x)**(-1/theta)-1)**(1/rho)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func3(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.exp(-grid**2+grid)**2)/d)\n",
    "    return np.exp(-grid**2+grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func2(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.exp(-grid)**2)/d)\n",
    "    return np.exp(-grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.sin(2*np.pi*grid)**2)/d)\n",
    "    return np.sin(2*np.pi*grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func5(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.sin(1/(1/12+grid**2))/d))\n",
    "    return np.sin(1/(1/12+grid**2))/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func6(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.cos(2*np.pi*grid+np.sin(1/(grid+1/10)))/d))\n",
    "    return np.cos(2*np.pi*grid+np.sin(1/(grid+1/10)))/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func7(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.cos(2*np.pi*grid)**2)/d)\n",
    "    return np.cos(2*np.pi*grid)/norm\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def beta_func4(d):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    norm=np.sqrt(np.sum(np.sin(2*np.pi*grid)**2)/d)\n",
    "    return np.sin(2*np.pi*grid)/norm\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def coeurjolly_cholesky_fbm_1D(d,H,sigma):\n",
    "    H2 = 2 * H\n",
    "    matcov = np.zeros((d-1,d-1))\n",
    "    for i in numba.prange(d-1):\n",
    "        for j in numba.prange(i,d-1):\n",
    "            r = (sigma**2)*(1/2)*(abs(i+1)**H2 + abs(j+1)**H2 - abs(j - i)**H2)\n",
    "            r = r/(d**H2)\n",
    "            matcov[i, j] = r\n",
    "            matcov[j, i] = matcov[i, j]\n",
    "    L = np.linalg.cholesky(matcov)\n",
    "    Z = npr.normal(0,1,size=(d - 1))\n",
    "    fBm = np.dot(L , Z)\n",
    "    #out=np.concatenate(([0], fBm))\n",
    "    # out=np.hstack(([0], fBm))\n",
    "    out= np.asarray([0] + list(fBm))\n",
    "    return out\n",
    "\n",
    "# @Article{RePEc:jss:jstsof:v:005:i07,\n",
    "#  author={Coeurjolly, Jean-Francois},\n",
    "#  title={{Simulation and identification of the fractional Brownian motion: a bibliographical and comparative study}},\n",
    "#  journal={Journal of Statistical Software},\n",
    "#  year=2000,\n",
    "#  volume={5},\n",
    "#  number={i07},\n",
    "#  pages={},\n",
    "#  month={},\n",
    "#  keywords={},\n",
    "#  doi={http://hdl.handle.net/10.18637/jss.v005.i07}\n",
    "#}\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def coeurjolly_cholesky_fbm_array(Z,H,sigma): # Z=npr.normal(0,1,size=(N,n,d - 1))\n",
    "    N=Z.shape[0]\n",
    "    n=Z.shape[1]\n",
    "    d=Z.shape[2]+1\n",
    "    out = np.zeros((N,n,d))\n",
    "    for p in numba.prange(N):\n",
    "        for q in numba.prange(n):    \n",
    "            H2 = 2 * H\n",
    "            matcov = np.zeros((d-1,d-1))\n",
    "            for i in numba.prange(d-1):\n",
    "                for j in numba.prange(i,d-1):\n",
    "                    r = (sigma**2)*(1/2)*(abs(i+1)**H2 + abs(j+1)**H2 - abs(j - i)**H2)\n",
    "                    r = r/(d**H2)\n",
    "                    matcov[i, j] = r\n",
    "                    matcov[j, i] = matcov[i, j]\n",
    "            L = np.linalg.cholesky(matcov)\n",
    "            fBm = np.dot(L , Z[p,q,:])\n",
    "            #out=np.concatenate(([0], fBm))\n",
    "            # out=np.hstack(([0], fBm))\n",
    "            out[p,q,:]= np.asarray([0] + list(fBm))\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def sigma(u,c,snr): \n",
    "    return (u**c)/snr\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def noise_mean(d,mu):\n",
    "    grid=np.linspace(0,1,d)\n",
    "    return mu*grid\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu): #Z = npr.normal(0,1,size=(N,n,d - 1))  \n",
    "                                     #Y = Pareto_iterated_sample(N,n,theta,s)\n",
    "    N=Y.shape[0]\n",
    "    n=Y.shape[1]\n",
    "    d=Z.shape[2]+1\n",
    "    out = np.zeros((N,n,d))\n",
    "    H2 = 2 * H\n",
    "    matcov = np.zeros((d-1,d-1))\n",
    "    for p in numba.prange(N):\n",
    "        for q in numba.prange(n):\n",
    "            matcov = np.zeros((d-1,d-1))\n",
    "            for i in numba.prange(d-1):\n",
    "                for j in numba.prange(i,d-1):\n",
    "                    r = (sigma(Y[p,q],c,snr)**2)*(1/2)*(abs(i+1)**H2 + abs(j+1)**H2 - abs(j - i)**H2)\n",
    "                    r = r/(d**H2)\n",
    "                    matcov[i, j] = r\n",
    "                    matcov[j, i] = matcov[i, j]\n",
    "            L = np.linalg.cholesky(matcov)\n",
    "            fBm = np.dot(L , Z[p,q,:])\n",
    "            out[p,q,:]= np.asarray([0]+list(fBm)) + noise_mean(d,mu)\n",
    "    return out\n",
    "\n",
    "################################################## Estimation\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def esdf(data,x): # Empirical Survival Distribution Function of Y. Here, x.shape = (N,) or (N,n) is the threshold\n",
    "    # data is Y and data.shape = (N,n)\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    if x.ndim == 1:\n",
    "        indicator_matrix = np.transpose(np.where(np.transpose(data)>x,1,0)) # binary matrix with same shape as data representating the indicator matrix 1_{X_ij<x_j}\n",
    "    if x.ndim == 2:\n",
    "        indicator_matrix = np.where(data>x,1,0)\n",
    "    return np.sum(indicator_matrix,axis=1)/n # (N,)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def threshold_index(X,Y,Y_sort_index,tau,m,start): # 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    out=np.zeros((N,))\n",
    "    aux=concomittant_corr(X,Y,Y_sort_index,tau,m)[:,start:]\n",
    "    return start+np.argmax(aux,axis=1)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def threshold(X,Y,Y_sort_index,tau,m,start): # 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    y_matrix_out = np.zeros((N,n))\n",
    "    YY=np.copy(Y)\n",
    "    Y_sort=sort_2d_array(YY)\n",
    "    index = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "    for i in numba.prange(N):\n",
    "        y_matrix_out[i,:] = Y_sort[i,n-index[i]-1]*np.ones((n,))\n",
    "    return y_matrix_out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def fepls_weight(Y,y_matrix,nu): # Y of size (N,n)\n",
    "                             # y_matrix of shape (N,n), for instance y_matrix = y*np.ones((N,n)) where y threshold\n",
    "                             # nu is such that \\psi(x) = x^nu\n",
    "    N=Y.shape[0]\n",
    "    n=Y.shape[1]\n",
    "    out=np.zeros((N,))\n",
    "    aux = Y**nu # size (N,n) - \\psi(Y_i)\n",
    "    aux2 = np.multiply(aux,np.greater_equal(Y,y_matrix)) # size (N,n) - Product \\psi(Y_i)*1_{Y_i \\ge y}\n",
    "    return np.sum(aux2,axis=1)/n # size (N,)\n",
    "\n",
    "#@numba.njit(parallel=True, fastmath=False) # It seems that \"greater_equal\" and numba don't work well together\n",
    "def fepls(X,Y,y_matrix,tau): # X of size (N,n,d) and Y of size (N,n)\n",
    "                             # y_matrix of shape (N,n), for instance y_matrix = y*np.ones((N,n)) where y threshold\n",
    "                             # tau is the tail index of \\vfi\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    out=np.zeros((N,d))\n",
    "    for j in range(d):\n",
    "        aux = np.multiply(X[:,:,j],Y**tau) # size (N,n,d) - Product \\vfi(Y_i)*X_i\n",
    "        out2 = np.multiply(aux,np.greater_equal(Y,y_matrix)) # size (N,n) - Product \\vfi(Y_i)*X_i*1_{Y_i \\ge y}\n",
    "        out[:,j]= np.sum(out2,axis=1)/n # (N,d)\n",
    "    norms=np.sqrt(np.sum(out**2,axis=1)/d) # length (N,)\n",
    "    out2 =  out * (norms.reshape((norms.size, 1)))**(-1)\n",
    "    return out2 # size (N,d)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def fepls_numba(X,Y,y_matrix,tau): # X of size (N,n,d) and Y of size (N,n)\n",
    "                             # y_matrix of shape (N,n), for instance y_matrix = y*np.ones((N,n)) where y threshold\n",
    "                             # tau is the tail index of \\vfi\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    out=np.zeros((N,d))\n",
    "    for j in numba.prange(d):\n",
    "        aux = np.multiply(X[:,:,j],Y**tau) # size (N,n,d) - Product \\vfi(Y_i)*X_i\n",
    "        out2 = np.multiply(aux,np.greater_equal(Y,y_matrix)) # size (N,n) - Product \\vfi(Y_i)*X_i*1_{Y_i \\ge y}\n",
    "        out[:,j]= np.sum(out2,axis=1)/n # (N,d)\n",
    "    norms=np.sqrt(np.sum(out**2,axis=1)/d) # length (N,)\n",
    "    out2 =  out * (norms.reshape((norms.size, 1)))**(-1)\n",
    "    return out2 # size (N,d)\n",
    "\n",
    "# g(t)= t^c with c \\in \\{1/4,1/2,1,3/2\\} \n",
    "# X = g(Y)\\beta + \\eps\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def Hill(Y,int_seq): # Y of size (N,n), y number, int_seq is an intermediate sequence, ie such that int_seq << n\n",
    "    N=Y.shape[0]\n",
    "    n=Y.shape[1]\n",
    "    Y_ord=np.copy(Y)\n",
    "    Y_ord=np.sort(Y_ord) \n",
    "    Y_2=Y_ord[:,n-int_seq-1]\n",
    "    aux=Y_ord/Y_2[:, None]\n",
    "    out=np.log(aux[:,0:n-int_seq])\n",
    "    return (1/int_seq)*np.sum(out,axis=1) # size (N,)\n",
    "\n",
    "#### Same as np.sort for 2D arrays but works with numba njit+parallel\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def sort_2d_array(x):\n",
    "    n,m=np.shape(x)\n",
    "    for row in numba.prange(n):\n",
    "        x[row]=np.sort(x[row])\n",
    "    return x\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def hatbeta_dot_beta(X,Y,tau,l):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    y_array=np.zeros((N,n,np.arange(int(n/l)).size))\n",
    "    out=np.zeros((N,np.arange(int(n/l)).size))\n",
    "    YY=np.copy(Y)\n",
    "    for p in numba.prange(int(n/l)):\n",
    "        y_array[:,0,p]=sort_2d_array(YY)[:,n-l*p-1]\n",
    "        for k in numba.prange(N):\n",
    "            y_array[k,:,p]=y_array[k,0,p]\n",
    "        hat_beta=fepls_numba(X,Y,y_array[:,:,p],tau) \n",
    "        out[:,p]=(1/d)*np.sum(np.multiply(hat_beta,X[:,p,:]),axis=1) \n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def concomittant_corr(X,Y,Y_sort_index,tau,m): # 1\\le m \\le n # Y_sort_index = np.argsort(Y,axis=1)\n",
    "    N = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    d = X.shape[2]\n",
    "    out = np.zeros((N,m))\n",
    "    YY=np.copy(Y)\n",
    "    Y_sort=sort_2d_array(YY)\n",
    "    for k in numba.prange(m):\n",
    "        y_array = np.zeros((N,n,k+1))\n",
    "        aux = np.zeros((N,k+1))\n",
    "        aux2 = np.zeros((N,k+1))\n",
    "        aux3 = Y_sort[:,n-k-1:] # shape (N,k+1)\n",
    "        aux3_sum = np.sum(aux3,axis=1)\n",
    "        for i in numba.prange(k):\n",
    "            y_array[:,0,i] = Y_sort[:,n-i-1]\n",
    "            for j_2 in numba.prange(N):\n",
    "                y_array[j_2,:,i] = y_array[j_2,0,i]\n",
    "            hat_beta = fepls_numba(X,Y,y_array[:,:,i],tau) \n",
    "            for j_1 in numba.prange(N):\n",
    "                i_c = Y_sort_index[j_1,i]\n",
    "                aux[j_1,i]=(1/d)*np.sum(np.multiply(hat_beta[j_1,:],X[j_1,i_c,:]))\n",
    "                aux2[j_1,i]= np.multiply(aux[j_1,i],Y_sort[j_1,n-i-1]) \n",
    "                out[j_1,k]= np.corrcoef(aux3[j_1,:],aux[j_1,:])[0,1]\n",
    "    return out\n",
    "    \n",
    "def bitcoin_concomittant_corr(X,Y,tau,m): # 1\\le m \\le n \n",
    "    N = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "    d = X.shape[2]\n",
    "    out = np.zeros((m))\n",
    "    Y_sort=np.sort(Y,axis=1)\n",
    "    Y_sort_index = np.argsort(Y,axis=1)\n",
    "    for k in range(m):\n",
    "        y_array = np.zeros((N,n,k+1))\n",
    "        aux = np.zeros((k+1))\n",
    "        aux2 = np.zeros((k+1))\n",
    "        aux3 = Y_sort[0,n-k-1:] # shape (k+1)\n",
    "        aux3_sum = np.sum(aux3)\n",
    "        for i in range(k):\n",
    "            y_array[:,:,i] = (Y_sort[0,n-i-1])*np.ones((1,n))\n",
    "            hat_beta = fepls(X,Y,y_array[:,:,i],tau) \n",
    "            i_c = Y_sort_index[0,i]\n",
    "            aux[i]=(1/d)*np.sum(np.multiply(hat_beta[0,:],X[0,i_c,:]))\n",
    "            aux2[i]= np.multiply(aux[i],Y_sort[0,n-i-1]) \n",
    "            out[k]= np.corrcoef(aux3,aux)[0,1]\n",
    "    return np.abs(out)\n",
    "\n",
    "def bitcoin_threshold_index(X,Y,tau,m,start): # 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    out = np.zeros((N,n))\n",
    "    return start+np.argmax(bitcoin_concomittant_corr(X,Y,tau,int(n/5))[start:])\n",
    "    \n",
    "def bitcoin_threshold(X,Y,tau,m,start):# 0\\le start \\le n-1\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    out = np.zeros((N,n))\n",
    "    Y_sort_index = np.argsort(Y,axis=1)\n",
    "    Y_sort=np.sort(Y,axis=1)\n",
    "    index = bitcoin_threshold_index(X,Y,tau,m,start)\n",
    "    out[0,:] = Y_sort[0,n-index-1]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def hatbeta_dot_X(X,hat_beta): # hat_beta=fepls(X,Y,y_matrix,tau) of shape (N,d)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    out=np.zeros((N,n))\n",
    "    for i in numba.prange(n):\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(hat_beta,X[:,i,:]),axis=1) \n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) # the same as np.dot(X,beta_func(d))/d (which is preferable)\n",
    "def beta_dot_X(X):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    out=np.zeros((N,n))\n",
    "    for i in numba.prange(n):\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func(d)),axis=1) \n",
    "    return out\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) # np.dot(X,beta_func(d))/d\n",
    "def beta_dot_X(X,beta_param):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    out=np.zeros((N,n))\n",
    "    for i in numba.prange(n):\n",
    "        if beta_param == 1:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func(d)),axis=1)\n",
    "        elif beta_param == 2:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func2(d)),axis=1)\n",
    "        elif beta_param == 3:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func3(d)),axis=1)\n",
    "        elif beta_param == 4:\n",
    "            out[:,i]=(1/d)*np.sum(np.multiply(X[:,i,:],beta_func4(d)),axis=1)\n",
    "    return out\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def conditional_cov_Y_hat_beta_X(X,Y,hat_beta,y_matrix,tau): #hat_beta = fepls(X,Y,y_matrix,tau)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    A=hatbeta_dot_X(X,hat_beta)\n",
    "    cov_A=np.zeros((N,))\n",
    "    cov_B=np.zeros((N,))\n",
    "    for k in numba.prange(N):\n",
    "        cov_A[k] = (((A[k,:])[Y[k,:]>y_matrix[k,:]])*((Y[k,:])[Y[k,:]>y_matrix[k,:]])).mean() - ((A[k,:])[Y[k,:]>y_matrix[k,:]]).mean()*((Y[k,:])[Y[k,:]>y_matrix[k,:]]).mean()\n",
    "    return cov_A\n",
    "\n",
    "#@numba.njit(parallel=True, fastmath=False) # does not work with numba (no idea why)\n",
    "def conditional_cov_Y_beta_X(X,Y,y):\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]    \n",
    "    B=beta_dot_X(X)\n",
    "    cov_B=np.zeros((N,))\n",
    "    for k in numba.prange(N):\n",
    "        cov_B[k] = (((B[k,:])[Y[k,:]>y])*((Y[k,:])[Y[k,:]>y])).mean()-((B[k,:])[Y[k,:]>y]).mean()*((Y[k,:])[Y[k,:]>y]).mean()\n",
    "    return cov_B\n",
    "\n",
    "def Exponential_QQ_Plot_1D(Y,k):\n",
    "    n=Y.shape[1]\n",
    "    out=np.zeros((k))\n",
    "    out2=np.zeros((k))\n",
    "    YY=np.sort(Y,axis=1)\n",
    "    for i in range(k):\n",
    "        out[i]=np.log((k+1)/(i+1))\n",
    "        out2[i]=  np.log(YY[0,n-i-1])-np.log(YY[0,-k])\n",
    "    return np.column_stack((out,out2))\n",
    "\n",
    "################################################## Conditional quantile estimation (2D+3D array)\n",
    "################# Application: Bitcoin/SP500 quantile\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def Epanechnikov_kernel_2D(x): # x is a np.array of shape (p,q);     W=np.where(np.abs(x)<=1,1,0)\n",
    "    out = np.zeros_like(x)\n",
    "    x=np.asarray(x)\n",
    "    for i in numba.prange(x.shape[0]):\n",
    "        for j in numba.prange(x.shape[1]):\n",
    "            if x[i,j]<=1 and x[i,j]>=0:\n",
    "                out[i,j] = np.multiply(3/2,1-np.power(x[i,j],2))\n",
    "            else:\n",
    "                out[i,j]=0\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def Epanechnikov_kernel_1D(x): # x is a np.array of shape (p);     W=np.where(np.abs(x)<=1,1,0)\n",
    "    out = np.zeros_like(x)\n",
    "    x=np.asarray(x)\n",
    "    for i in numba.prange(x.shape[0]):\n",
    "        if x[i]<=1 and x[i]>=0:\n",
    "            out[i] = np.multiply(3/2,1-np.power(x[i],2))\n",
    "        else:\n",
    "            out[i]=0\n",
    "    return out\n",
    "    \n",
    "@numba.njit(parallel=False, fastmath=False) \n",
    "def Gaussian_kernel(x):\n",
    "    return (1/np.sqrt(2*np.pi))*np.exp(-0.5*np.power(x,2))\n",
    "\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def univariate_Nadaraya_weight(X_dimred,x,h,kernel): # X_dimred of shape (N,n) just as Y \n",
    "    # e.g., X_dimred = hatbeta_dot_X(X,hat_beta) = F0\n",
    "    # hat_beta=fepls(X,Y,y_matrix,tau)=E0; x real and h positive\n",
    "    N=X_dimred.shape[0]\n",
    "    n=X_dimred.shape[1]\n",
    "    out=np.zeros((N,n))\n",
    "    if kernel == 1:\n",
    "        K_h=Epanechnikov_kernel_2D((X_dimred-x)/h) # shape (N,n)\n",
    "    if kernel == 2:\n",
    "        K_h=Gaussian_kernel((X_dimred-x)/h) # shape (N,n)\n",
    "    return K_h/np.sum(K_h) ### shape = (N,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_test_2D(X,Y,X_dimred,inner_prod,x_func,alpha,a,b,m,h,h_func,kernel): # X_dimred.shape = Y.shape = (N,n), e.g., X_dimred = hatbeta_dot_X(X,hat_beta) = F0\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]; h_func is positive\n",
    "    # x_func_dot_beta.shape in \\R; it represents the inner product between x_func (where we project for the plot) and the vector in H reducing the dimension\n",
    "    # inner_prod.shape \\in\\R represents (x_func,beta)\n",
    "    #  beta is reducing the dimension, i.e., X_dimred=(X,beta).\n",
    "    # X_dimred = (X,beta); Y|X_dimred = x vs Y|X=x*x_func  \n",
    "    out = np.zeros((m,2))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func,kernel) \n",
    "        weight1=univariate_Nadaraya_weight(X_dimred,x_grid[p]*inner_prod,h,kernel)[0,:]  \n",
    "        out[p,0]=weighted_quantile(Y[0,:],weight1,alpha)\n",
    "        out[p,1]=weighted_quantile(Y[0,:],weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def univariate_Nadaraya_weight_2D(X_2D,dimred,x_func,x,h,type,kernel): # X of shape (n,d), Y of shape (n), dimred and x_func of shape (d,)\n",
    "    # dimred of shape (d,) is e.g. beta_func(d) or (fepls(X,Y,y_matrix,tau))[0,:]\n",
    "    # Y|(X,dimred)=(x_func,dimred) (type 1) vs Y|(X,dimred) = x (type 2)\n",
    "    d=x_func.shape[0]\n",
    "    if type == 1:\n",
    "        if kernel == 1:\n",
    "            K_h=Epanechnikov_kernel_1D((np.dot(X_2D,dimred)/d-np.dot(x_func,dimred)/d)/h) # shape (n,)\n",
    "        if kernel == 2:\n",
    "            K_h=Gaussian_kernel((np.dot(X_2D,dimred)/d-np.dot(x_func,dimred)/d)/h) # shape (n,)\n",
    "    if type == 2:     \n",
    "        if kernel == 1:\n",
    "            K_h=Epanechnikov_kernel_1D((np.dot(X_2D,dimred)/d-x)/h) # shape (n,)\n",
    "        if kernel == 2:\n",
    "            K_h=Gaussian_kernel((np.dot(X_2D,dimred)/d-x)/h) # shape (n,)\n",
    "    return K_h/np.sum(K_h) ### shape = (,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def functional_Nadaraya_weight_2D(X_2D,x_func,h,kernel): # X.shape = (n,d); h is positive ; x_func \\in H ie of shape (d,)\n",
    "    d=x_func.shape[0]\n",
    "    aux = (X_2D-x_func*np.ones(d))**2 # shape = (n,d)\n",
    "    norm = np.sqrt((1/d)*np.sum(aux,axis=1)) # shape = (n,)\n",
    "    if kernel == 1:\n",
    "        K_h= Epanechnikov_kernel_1D(norm/h) # shape = (n,)\n",
    "    if kernel == 2:\n",
    "        K_h= Gaussian_kernel(norm/h)## shape = (n,)\n",
    "    return K_h/np.sum(K_h) ### shape = (n,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def univariate_Nadaraya_weight_3D(X,dimred_2D,x_func,x,h,type,kernel): # X of shape (N,n,d), Y of shape (N,n), dimred_2D of shape (N,d)\n",
    "    # x_func of shape (d,) is e.g. beta_func(d) or (fepls(X,Y,y_matrix,tau))[0,:]\n",
    "    # x is a real number (e.g., x=x_grid[p] for p \\leq m)\n",
    "    # Y|(X,dimred)=(x_func,dimred) (type 1) vs Y|(X,dimred) = x (type 2)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    K_h = np.zeros((N,n))\n",
    "    for i in numba.prange(N):\n",
    "        if type == 1:\n",
    "            if kernel == 1:\n",
    "                K_h[i,:]=Epanechnikov_kernel_1D((np.dot(X[i,:,:],dimred_2D[i,:])/d-np.dot(x_func,dimred_2D[i,:])/d)/h) # shape (n,)\n",
    "            if kernel == 2:\n",
    "                K_h[i,:]=Gaussian_kernel((np.dot(X[i,:,:],dimred_2D[i,:])/d-np.dot(x_func,dimred_2D[i,:])/d)/h) # shape (n,)\n",
    "        if type == 2:\n",
    "            if kernel == 1:\n",
    "                K_h[i,:]=Epanechnikov_kernel_1D((np.dot(X[i,:,:],dimred_2D[i,:])/d-x)/h) # shape (n,)   \n",
    "            if kernel == 2:\n",
    "                K_h[i,:]=Gaussian_kernel((np.dot(X[i,:,:],dimred_2D[i,:])/d-x)/h) # shape (n,)\n",
    "    return np.transpose(np.transpose(K_h)/np.sum(K_h,axis=1)) ### shape = (N,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def functional_Nadaraya_weight_3D(X,x_func,h_func_2D,kernel): # X.shape = (N,n,d); h_func_2D.shape = (N,n); x_func \\in H ie of shape (d,)\n",
    "    N=X.shape[0]\n",
    "    n=X.shape[1]\n",
    "    d=X.shape[2]\n",
    "    aux = np.zeros((N,n,d))\n",
    "    for i in numba.prange(N):\n",
    "        aux[i,:,:] = (X[i,:,:]-x_func*np.ones(d))**2\n",
    "    norm = np.sqrt((1/d)*np.sum(aux,axis=2))\n",
    "    if kernel == 1:\n",
    "        K_h= Epanechnikov_kernel_2D(norm/h_func_2D)\n",
    "    if kernel == 2:\n",
    "        K_h= Gaussian_kernel(norm/h_func_2D)      \n",
    "    return np.transpose(np.transpose(K_h)/np.sum(K_h,axis=1)) ### shape = (N,n)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)   \n",
    "def weighted_quantile(data,weight,alpha):  # data.shape=weight.shape=(n,) \n",
    "    # alpha is the treshold in (0,1)\n",
    "    sorter = np.argsort(data)\n",
    "    data = data[sorter]\n",
    "    weight = weight[sorter]\n",
    "    weighted_quantiles = np.cumsum(weight) - 0.5 * weight\n",
    "    weighted_quantiles /= np.sum(weight)\n",
    "    return np.interp(alpha, weighted_quantiles, data)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def iterated_weq_2D(data_2D,weight,alpha): # same treshold for all marginals and iterations \n",
    "    # data.shape = (N,n); weight.shape=(N,n)\n",
    "    N=data_2D.shape[0]\n",
    "    n=data_2D.shape[1]\n",
    "    out = np.zeros((N,))\n",
    "    for k in numba.prange(N):\n",
    "        out[k]=weighted_quantile(data_2D[k,:],weight[k,:],alpha)\n",
    "    return out # shape = (N)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_dimred_vs_func_2D(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h,h_func,kernel): # dimred1,2 and x_func of shape (d,), e.g., dimred = E0[0,:] with E0 = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    out = np.zeros((m,3))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        #weight_func=functional_Nadaraya_weight(X,x_grid[p]*x_func,h)[0,:]#functional_Nadaraya_weight_Bitcoin(X,x_grid[p]*x_func,h)\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func,kernel)\n",
    "        weight1=univariate_Nadaraya_weight_2D(X[0,:,:],dimred1,x_grid[p]*x_func,x_grid[p],h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_2D(X[0,:,:],dimred2,x_grid[p]*x_func,x_grid[p],h,2,kernel)\n",
    "        out[p,0]=weighted_quantile(Y[0,:],weight1,alpha)\n",
    "        out[p,1]=weighted_quantile(Y[0,:],weight2,alpha)\n",
    "        out[p,2]=weighted_quantile(Y[0,:],weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_dimred_vs_func_2D_total(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h_vector,h_func_vector,kernel): # dimred1,2 and x_func of shape (d,), e.g., dimred = E0[0,:] with E0 = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "    # h_vector.shape = h_func_vector.shape = (m,)\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    out = np.zeros((m,3))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        #weight_func=functional_Nadaraya_weight(X,x_grid[p]*x_func,h)[0,:]#functional_Nadaraya_weight_Bitcoin(X,x_grid[p]*x_func,h)\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func_vector[p],kernel)\n",
    "        weight1=univariate_Nadaraya_weight_2D(X[0,:,:],dimred1,x_grid[p]*x_func,x_grid[p],h_vector[p],1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_2D(X[0,:,:],dimred2,x_grid[p]*x_func,x_grid[p],h_vector[p],2,kernel)\n",
    "        out[p,0]=weighted_quantile(Y[0,:],weight1,alpha)\n",
    "        out[p,1]=weighted_quantile(Y[0,:],weight2,alpha)\n",
    "        out[p,2]=weighted_quantile(Y[0,:],weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def plot_quantile_covariate_dimred_vs_func_3D(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h,h_func_2D,kernel): # dimred1,2 of shape (N,d), e.g., dimred = E = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "    # h_func_2D.shape = (N,n)\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    N=X.shape[0]\n",
    "    out = np.zeros((N,m,3))\n",
    "    x_grid = np.linspace(a,b,m)\n",
    "    for p in numba.prange(m):\n",
    "        weight_func=functional_Nadaraya_weight_3D(X,x_grid[p]*x_func,h_func_2D,kernel)\n",
    "        weight1=univariate_Nadaraya_weight_3D(X,dimred1,x_grid[p]*x_func,x_grid[p],h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_3D(X,dimred2,x_grid[p]*x_func,x_grid[p],h,2,kernel)\n",
    "        out[:,p,0]=iterated_weq_2D(Y,weight1,alpha)\n",
    "        out[:,p,1]=iterated_weq_2D(Y,weight2,alpha)\n",
    "        out[:,p,2]=iterated_weq_2D(Y,weight_func,alpha)\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def plot_quantile_alpha_dimred_vs_func_3D(X,Y,dimred1,dimred2,x_func,x,a,b,m,h,h_func,type,kernel): # dimred of shape (N,d), e.g., dimred = E = fepls(X,Y,y_matrix,tau)\n",
    "    # x_func = any vector in H, eg beta_func(d) or E0[0,:]\n",
    "   # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    N=X.shape[0]\n",
    "    out = np.zeros((N,m,3))\n",
    "    alpha_grid = np.linspace(0,1,m)\n",
    "    for p in range(m):\n",
    "        weight_func=functional_Nadaraya_weight_3D(X,x_func,h_func,kernel)\n",
    "        weight1=univariate_Nadaraya_weight_3D(X,dimred1,x_func,x,h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_3D(X,dimred2,x_func,x,h,2,kernel)\n",
    "        out[:,p,0]=iterated_weq_2D(Y,weight1,alpha_grid[p])\n",
    "        out[:,p,1]=iterated_weq_2D(Y,weight1,alpha_grid[p])\n",
    "        out[:,p,2]=iterated_weq_2D(Y,weight_func,alpha_grid[p])\n",
    "    return out\n",
    "\n",
    "################################################## ][ Tail index  \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def get_hill_estimator(ordered_data):\n",
    "    \"\"\"\n",
    "    Function to calculate Hill estimator array given an ordered data\n",
    "    sequence. Decreasing ordering is required; e.g. ordered_data = np.sort(data[0,:])[::-1] where data might be Y (of shape (N,n))\n",
    "    :param ordered_data: numpy array of ordered data for which the 1st moment (Hill estimator) is calculated.\n",
    "    :return: numpy array of Hill estimator corresponding to all possible order statistics of the dataset.\n",
    "    \"\"\"\n",
    "    logs = np.log(ordered_data)\n",
    "    logs_cumsum = np.cumsum(logs[:-1])\n",
    "    k_vector = np.arange(1, len(ordered_data))\n",
    "    m1 = (1./k_vector)*logs_cumsum - logs[1:]\n",
    "    return m1\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def get_hill_estimator_2D(ordered_data_2D): # ordered_data_2D = np.sort(-data,axis=1)*-1 with data 2D-array\n",
    "    \"\"\"\n",
    "    Function to calculate Hill estimator array given an ordered data; e.g., ordered_data_2D = np.sort(-Y,axis=1)*-1\n",
    "    sequence. Decreasing ordering is required; e.g. ordered_data = np.sort(data[0,:])[::-1] where data might be Y (of shape (N,n))\n",
    "    :param ordered_data: numpy array of ordered data for which the 1st moment (Hill estimator) is calculated.\n",
    "    :return: numpy array of Hill estimator corresponding to all possible order statistics of the dataset.\n",
    "    \"\"\"\n",
    "    N=ordered_data_2D.shape[0]\n",
    "    n=ordered_data_2D.shape[1]\n",
    "    m1=np.zeros((N,n-1))\n",
    "    for i in numba.prange(N):\n",
    "        logs = np.log(ordered_data_2D[i,:]) \n",
    "        logs_cumsum = np.cumsum(logs[:-1])\n",
    "        k_vector = np.arange(1, len(ordered_data_2D[i,:]))\n",
    "        m1[i,:] = (1./k_vector)*logs_cumsum - logs[1:]\n",
    "    return m1\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def Hill_estimator_one_value(ordered_data, k):\n",
    "    \"\"\"\n",
    "    Function to calculate the Hill estimator for a specified order statistic k. Decreasing ordering is required.\n",
    "    :param ordered_data: Decreasingly ordered sample; e.g. ordered_data = np.sort(data[0,:])[::-1] where data might be Y (of shape (N,n))\n",
    "    :param k: from 1 up to and including len(ordered_data) - 1\n",
    "    :return: float with the value of the Hill estimator\n",
    "    \"\"\"\n",
    "    selected_logs = np.log(ordered_data[:k+1])\n",
    "    return 1./k * sum(selected_logs[:-1]) - selected_logs[-1]\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def Hill_estimator_one_value_2D(ordered_data_2D, k): # ordered_data_2D = np.sort(-data,axis=1)*-1 with data 2D-array\n",
    "    N=ordered_data_2D.shape[0]\n",
    "    n=ordered_data_2D.shape[1]\n",
    "    out=np.zeros((N,))\n",
    "    for i in numba.prange(N):\n",
    "        selected_logs = np.log(ordered_data_2D[i,:k+1])\n",
    "        out[i]=1./k * sum(selected_logs[:-1]) - selected_logs[-1]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def tail_index_gamma_estimator(data,weight,alpha,J): \n",
    "    N=data.shape[0]\n",
    "    d=data.shape[2]\n",
    "    subdivision=np.array([(1/s) for s in np.arange(1,J+1)] )\n",
    "    quantile_data2=iterated_weq(data,weight,alpha) # quantile_data2.shape=(N,d)\n",
    "    out=np.zeros((N,))\n",
    "    aux=np.zeros((N,J))\n",
    "    for k in numba.prange(N):\n",
    "        for j in numba.prange(J):\n",
    "            quantile_data1=iterated_weq(data,weight,1-subdivision[j]*(1-alpha))\n",
    "            aux[k,j] = np.log(quantile_data1[k,0])-np.log(quantile_data2[k,0])\n",
    "            aux[k,j] /= -np.sum(np.log(subdivision))\n",
    "        out[k] = np.sum(aux[k,:])\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def tail_index_gamma_estimator_2D(Y,weight,alpha,J):  # Y.shape= (N,n); weight.shape = (n,)\n",
    "    subdivision=np.array([(1/s) for s in np.arange(1,J+1)] )\n",
    "    quantile_data2=weighted_quantile(Y[0,:],weight,alpha) # \n",
    "    aux=np.zeros((J))\n",
    "    for j in numba.prange(J):\n",
    "        quantile_data1=weighted_quantile(Y[0,:],weight,1-subdivision[j]*(1-alpha))\n",
    "        aux[j] = np.log(quantile_data1)-np.log(quantile_data2)\n",
    "        aux[j] /= -np.sum(np.log(subdivision))\n",
    "    return np.sum(aux)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False)  \n",
    "def plot_tail_index_all_2D(X,Y,dimred1,dimred2,x_func,alpha,a,b,m,h,h_func,J,kernel): # Y.shape = (N,n); X.shape = (N,n,d); Y.shape = (n); x_func.shape = (d,); J=9\n",
    "    # dimred1.shape = dimred2.shape = (d,)\n",
    "    # Y|(X,dimred1)=(x*x_func,dimred1) (type 1) vs Y|(X,dimred2) = x (type 2) vs Y|X = x*x_func (type functional)\n",
    "    x_grid=np.linspace(a,b,m)\n",
    "    out=np.zeros((m,3))\n",
    "    for p in numba.prange(m):\n",
    "        weight1=univariate_Nadaraya_weight_2D(X[0,:,:],dimred1,x_grid[p]*x_func,x_grid[p],h,1,kernel)\n",
    "        weight2=univariate_Nadaraya_weight_2D(X[0,:,:],dimred2,x_grid[p]*x_func,x_grid[p],h,2,kernel)\n",
    "        weight_func=functional_Nadaraya_weight_2D(X[0,:,:],x_grid[p]*x_func,h_func,kernel)\n",
    "        out[p,0]=tail_index_gamma_estimator_2D(Y,weight1,alpha,J)\n",
    "        out[p,1]=tail_index_gamma_estimator_2D(Y,weight2,alpha,J)\n",
    "        out[p,2]=tail_index_gamma_estimator_2D(Y,weight_func,alpha,J)\n",
    "    return out\n",
    "\n",
    "################################################## ][ Copula \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def marginal_wecdf(data,weight,x_vect): # x row vector of length d (each marginal has its own treshold)\n",
    "    # e.g. for uniform treshold t, x_vect=x*np.ones((d,))\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n)\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    out=np.zeros((N,d))\n",
    "    for k in numba.prange(N):\n",
    "        for j in numba.prange(d):\n",
    "            indicator_matrix = np.where(data[:,:,j]<x_vect[j],1,0) # binary matrix with same shape as data representating the indicator matrix 1_{X_ij<x_j}\n",
    "            out[k,j]= np.sum(np.multiply(indicator_matrix[k,:],weight[k,:]))\n",
    "    return out/n # (N,d)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False)\n",
    "def rank(U): # U.shape = (N,n,d)\n",
    "    R = np.empty_like(U)\n",
    "    for p in numba.prange(U.shape[0]):\n",
    "        for j in numba.prange(U.shape[2]):\n",
    "            R[p,:, j] = np.argsort(np.argsort(U[p,:, j]))+1\n",
    "    return R\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def weighted_ranked_data(R,weight): # ie: \\hat{F}_{j,n,y}(X_ij); R = rank(data) with shape (N,n,d); weight.shape=(N,n)\n",
    "    N=R.shape[0]\n",
    "    n=R.shape[1]\n",
    "    d=R.shape[2]\n",
    "    out=np.zeros((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            for j in numba.prange(d):\n",
    "                r=np.int32(R[k,i,j])\n",
    "                out[k,i,j]=np.sum(weight[k,0:r])\n",
    "    return out/n \n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_indicator(data,j,k,x,y): # data.shape = (N,n,d); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    A=np.where(data[:,:,j]<x,1,0)\n",
    "    B=np.where(data[:,:,k]<y,1,0)\n",
    "    return np.multiply(A,B) # shape = (N,n)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_anti_indicator(data,j,k,x,y): # data.shape = (N,n,d); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    A=np.where(data[:,:,j]<x,0,1)\n",
    "    B=np.where(data[:,:,k]<y,0,1)\n",
    "    return np.multiply(A,B) # shape = (N,n)\n",
    "    \n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_wecdf(data,weight,j_1,j_2,x,y):\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    biv_indicator=bivariate_indicator(data,j_1,j_2,x,y)\n",
    "    return np.sum(np.multiply(biv_indicator,weight),axis=1)/n # shape = (N,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_ecdf(data,j_1,j_2,x,y):\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    biv_indicator=bivariate_indicator(data,j_1,j_2,x,y)\n",
    "    return np.sum((biv_indicator),axis=1)/n # shape = (N,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def bivariate_survival_wecdf(data,weight,j_1,j_2,x,y):\n",
    "    # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j\\neq k \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    biv_indicator=bivariate_anti_indicator(data,j_1,j_2,x,y)\n",
    "    return np.sum(np.multiply(biv_indicator,weight),axis=1)/n # shape = (N,)\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def empirical_uniform_data(data,weight): \n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    out = np.zeros((N,n,d))\n",
    "    for k in numba.prange(N):\n",
    "        for i in numba.prange(n):\n",
    "            out[k,i,:]=marginal_wecdf(data,weight,data[k,i,:])[k,:]\n",
    "    return out\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def weighted_empirical_copula(data,weight,j_1,j_2,u,v): # u.shape = (2,) in (0,1)\n",
    "        # data.shape = (N,n,d); weight.shape=(N,n); 1\\le j_1\\neq j_2 \\le d\n",
    "    N=data.shape[0]\n",
    "    n=data.shape[1]\n",
    "    d=data.shape[2]\n",
    "    out=np.zeros((N,n))\n",
    "    data=empirical_uniform_data(data,weight)\n",
    "    biv_indicator=bivariate_indicator(emp_unif_data,j_1,j_2,u,v)\n",
    "    out= np.multiply(biv_indicator,weight)/n \n",
    "    return np.sum(out,axis=1) # return (N)-shape\n",
    "\n",
    "@numba.njit(parallel=True, fastmath=False) \n",
    "def weighted_ranked_empirical_copula(weighted_ranked_data,weight,j_1,j_2,u,v): # u,v in (0,1)\n",
    "        # weighted_ranked_data=weighted_ranked_data(R.astype(int),weight) where R=rank(data); \n",
    "        # weighted_ranked_data.shape = (N,n,d) is ; weight.shape=(N,n); 1\\le j_1\\neq j_2 \\le d\n",
    "    N=weighted_ranked_data.shape[0]\n",
    "    n=weighted_ranked_data.shape[1]\n",
    "    d=weighted_ranked_data.shape[2]\n",
    "    out=np.zeros((N,n))\n",
    "    biv_indicator=bivariate_indicator(weighted_ranked_data,j_1,j_2,u,v)\n",
    "    out= np.multiply(biv_indicator,weight)/n \n",
    "    return np.sum(out,axis=1) # return (N)-shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid!\n",
      "None\n",
      "Time cost 37.641029357910156\n"
     ]
    }
   ],
   "source": [
    "################################################## Execute (Synthetic Data)\n",
    "\n",
    "N=50\n",
    "n=50\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 1 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Y_sim=Y\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold(X,Y,Y_sort_index,tau,100,start)\n",
    "E = fepls(X,Y,y_matrix,tau)\n",
    "#E2 = fepls_numba(X,Y,y_matrix,tau) # Same but not parallelizable and slower...\n",
    "#F=hatbeta_dot_X(X,E)\n",
    "\n",
    "#############################################################################\n",
    "print(check_cond_no_q(gamma,c,tau))\n",
    "print(\"Time cost\",time.time()-tic)\n",
    "##################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGdCAYAAACyzRGfAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjcsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvTLEjVAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGvlJREFUeJzt3X2QVXX9wPHPArKg7i4tAsvGgogJimKlhOsDPqFIxmiiKdGED1nZiiGj5jY+kdqizSg9IKYVaAaW41PaKCOYOI6ggKGSI4qpYDxYJnthzaux9/dH0/7awIeFu9/LXl+vmTPDPffsOR/PrHPfc/bce0tyuVwuAAAS6VToAQCATxbxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASXUp9AD/q7m5OdauXRtlZWVRUlJS6HEAgI8hl8vFpk2borq6Ojp1+vBrGztdfKxduzZqamoKPQYAsB3WrFkT/fr1+9Btdrr4KCsri4h/D19eXl7gaQCAjyOTyURNTU3L6/iH2eni4z9/aikvLxcfANDBfJxbJtxwCgAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICk2hQfM2fOjGHDhrV89HltbW089NBDLc+/++67UVdXFz179ozdd989xo0bFxs2bMj70ABAx9Wm+OjXr19MmzYtli1bFkuXLo1jjjkmTjrppPjzn/8cEREXXnhhPPDAA3HXXXfFwoULY+3atXHKKae0y+AAQMdUksvlcjuyg8rKyvjRj34Up556avTq1SvmzJkTp556akREvPjii7HvvvvGokWL4pBDDvlY+8tkMlFRURGNjY2+WA4AOoi2vH5v9z0fW7ZsiTvvvDOampqitrY2li1bFu+//36MGjWqZZshQ4ZE//79Y9GiRR+4n2w2G5lMptUCABSvLm39geeffz5qa2vj3Xffjd133z3uvffe2G+//WL58uXRtWvX6NGjR6vt+/TpE+vXr//A/TU0NMTUqVPbPPj22vPSPyQ7Vr68Nu3EQo8AAHnT5isfgwcPjuXLl8dTTz0V5513XkycODFeeOGF7R6gvr4+GhsbW5Y1a9Zs974AgJ1fm698dO3aNfbee++IiDjooINiyZIl8eMf/zhOP/30eO+992Ljxo2trn5s2LAhqqqqPnB/paWlUVpa2vbJAYAOaYc/56O5uTmy2WwcdNBBscsuu8SCBQtanlu5cmWsXr06amtrd/QwAECRaNOVj/r6+hgzZkz0798/Nm3aFHPmzInHHnss5s2bFxUVFXHOOefElClTorKyMsrLy2PSpElRW1v7sd/pAgAUvzbFx5tvvhlf//rXY926dVFRURHDhg2LefPmxXHHHRcRETfeeGN06tQpxo0bF9lsNkaPHh033XRTuwwOAHRMO/w5H/nW3p/z4d0uAJB/ST7nAwBge4gPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEiqTfHR0NAQw4cPj7Kysujdu3ecfPLJsXLlylbbHHXUUVFSUtJq+fa3v53XoQGAjqtN8bFw4cKoq6uLxYsXxyOPPBLvv/9+HH/88dHU1NRqu3PPPTfWrVvXslx//fV5HRoA6Li6tGXjhx9+uNXj2bNnR+/evWPZsmUxcuTIlvW77rprVFVV5WdCAKCo7NA9H42NjRERUVlZ2Wr9b37zm9hjjz1i//33j/r6+njnnXc+cB/ZbDYymUyrBQAoXm268vHfmpubY/LkyXHYYYfF/vvv37L+q1/9agwYMCCqq6vjueeei+9973uxcuXKuOeee7a5n4aGhpg6der2jgEAdDAluVwutz0/eN5558VDDz0UTzzxRPTr1+8Dt3v00Ufj2GOPjVWrVsWgQYO2ej6bzUY2m215nMlkoqamJhobG6O8vHx7RvtQe176h7zvs729Nu3EQo8AAB8qk8lERUXFx3r93q4rH+eff348+OCD8fjjj39oeEREjBgxIiLiA+OjtLQ0SktLt2cMAKADalN85HK5mDRpUtx7773x2GOPxcCBAz/yZ5YvXx4REX379t2uAQGA4tKm+Kirq4s5c+bE/fffH2VlZbF+/fqIiKioqIju3bvHK6+8EnPmzIkvfvGL0bNnz3juuefiwgsvjJEjR8awYcPa5T8AAOhY2hQfM2fOjIh/f5DYf5s1a1aceeaZ0bVr15g/f35Mnz49mpqaoqamJsaNGxeXXXZZ3gYGADq2Nv/Z5cPU1NTEwoULd2ggAKC4+W4XACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEiqTfHR0NAQw4cPj7Kysujdu3ecfPLJsXLlylbbvPvuu1FXVxc9e/aM3XffPcaNGxcbNmzI69AAQMfVpvhYuHBh1NXVxeLFi+ORRx6J999/P44//vhoampq2ebCCy+MBx54IO66665YuHBhrF27Nk455ZS8Dw4AdExd2rLxww8/3Orx7Nmzo3fv3rFs2bIYOXJkNDY2xi9/+cuYM2dOHHPMMRERMWvWrNh3331j8eLFccghh+RvcgCgQ9qhez4aGxsjIqKysjIiIpYtWxbvv/9+jBo1qmWbIUOGRP/+/WPRokU7cigAoEi06crHf2tubo7JkyfHYYcdFvvvv39ERKxfvz66du0aPXr0aLVtnz59Yv369dvcTzabjWw22/I4k8ls70gAQAew3Vc+6urqYsWKFXHnnXfu0AANDQ1RUVHRstTU1OzQ/gCAndt2xcf5558fDz74YPzxj3+Mfv36tayvqqqK9957LzZu3Nhq+w0bNkRVVdU291VfXx+NjY0ty5o1a7ZnJACgg2hTfORyuTj//PPj3nvvjUcffTQGDhzY6vmDDjoodtlll1iwYEHLupUrV8bq1aujtrZ2m/ssLS2N8vLyVgsAULzadM9HXV1dzJkzJ+6///4oKytruY+joqIiunfvHhUVFXHOOefElClTorKyMsrLy2PSpElRW1vrnS4AQES0MT5mzpwZERFHHXVUq/WzZs2KM888MyIibrzxxujUqVOMGzcustlsjB49Om666aa8DAsAdHxtio9cLveR23Tr1i1mzJgRM2bM2O6hAIDi5btdAICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJNXm+Hj88cdj7NixUV1dHSUlJXHfffe1ev7MM8+MkpKSVssJJ5yQr3kBgA6uzfHR1NQUBx54YMyYMeMDtznhhBNi3bp1LcvcuXN3aEgAoHh0aesPjBkzJsaMGfOh25SWlkZVVdV2DwUAFK92uefjsccei969e8fgwYPjvPPOi7feeusDt81ms5HJZFotAEDxynt8nHDCCXH77bfHggUL4rrrrouFCxfGmDFjYsuWLdvcvqGhISoqKlqWmpqafI8EAOxE2vxnl49yxhlntPz7gAMOiGHDhsWgQYPisccei2OPPXar7evr62PKlCktjzOZjAABgCLW7m+13WuvvWKPPfaIVatWbfP50tLSKC8vb7UAAMWr3ePjjTfeiLfeeiv69u3b3ocCADqANv/ZZfPmza2uYrz66quxfPnyqKysjMrKypg6dWqMGzcuqqqq4pVXXolLLrkk9t577xg9enReBwcAOqY2x8fSpUvj6KOPbnn8n/s1Jk6cGDNnzoznnnsubrvttti4cWNUV1fH8ccfH1dffXWUlpbmb2oAoMNqc3wcddRRkcvlPvD5efPm7dBAAEBx890uAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkmpzfDz++OMxduzYqK6ujpKSkrjvvvtaPZ/L5eKKK66Ivn37Rvfu3WPUqFHx8ssv52teAKCDa3N8NDU1xYEHHhgzZszY5vPXX399/OQnP4mbb745nnrqqdhtt91i9OjR8e677+7wsABAx9elrT8wZsyYGDNmzDafy+VyMX369LjsssvipJNOioiI22+/Pfr06RP33XdfnHHGGTs2LQDQ4eX1no9XX3011q9fH6NGjWpZV1FRESNGjIhFixZt82ey2WxkMplWCwBQvPIaH+vXr4+IiD59+rRa36dPn5bn/ldDQ0NUVFS0LDU1NfkcCQDYyRT83S719fXR2NjYsqxZs6bQIwEA7Siv8VFVVRURERs2bGi1fsOGDS3P/a/S0tIoLy9vtQAAxSuv8TFw4MCoqqqKBQsWtKzLZDLx1FNPRW1tbT4PBQB0UG1+t8vmzZtj1apVLY9fffXVWL58eVRWVkb//v1j8uTJcc0118RnPvOZGDhwYFx++eVRXV0dJ598cj7nBgA6qDbHx9KlS+Poo49ueTxlypSIiJg4cWLMnj07LrnkkmhqaopvfvObsXHjxjj88MPj4Ycfjm7duuVvagCgwyrJ5XK5Qg/x3zKZTFRUVERjY2O73P+x56V/yPs+29tr004s9AgA8KHa8vpd8He7AACfLOIDAEhKfAAASYkPACAp8QEAJNXmt9rCx+FdRQB8EFc+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKTyHh9XXXVVlJSUtFqGDBmS78MAAB1Ul/bY6dChQ2P+/Pn/f5Au7XIYAKADapcq6NKlS1RVVbXHrgGADq5d7vl4+eWXo7q6Ovbaa6+YMGFCrF69uj0OAwB0QHm/8jFixIiYPXt2DB48ONatWxdTp06NI444IlasWBFlZWVbbZ/NZiObzbY8zmQy+R4JANiJ5D0+xowZ0/LvYcOGxYgRI2LAgAHxu9/9Ls4555yttm9oaIipU6fmewwAYCfV7m+17dGjR+yzzz6xatWqbT5fX18fjY2NLcuaNWvaeyQAoIDaPT42b94cr7zySvTt23ebz5eWlkZ5eXmrBQAoXnmPj4suuigWLlwYr732Wjz55JPx5S9/OTp37hzjx4/P96EAgA4o7/d8vPHGGzF+/Ph46623olevXnH44YfH4sWLo1evXvk+FADQAeU9Pu6888587xIAKCK+2wUASEp8AABJiQ8AICnxAQAkJT4AgKR81z10YHte+odCj9Bmr007sdAjQF75/7DtXPkAAJISHwBAUuIDAEhKfAAASYkPACAp8QEAJCU+AICkxAcAkJT4AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AICnxAQAkJT4AgKS6FHoAgJ3dnpf+odAjbJfXpp1Y6BFgm1z5AACSEh8AQFLiAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASMp3uwCw0+io36ND27jyAQAkJT4AgKTEBwCQlPgAAJISHwBAUuIDAEiq3eJjxowZseeee0a3bt1ixIgR8fTTT7fXoQCADqRd4uO3v/1tTJkyJa688sp45pln4sADD4zRo0fHm2++2R6HAwA6kHaJjxtuuCHOPffcOOuss2K//faLm2++OXbdddf41a9+1R6HAwA6kLx/wul7770Xy5Yti/r6+pZ1nTp1ilGjRsWiRYu22j6bzUY2m2153NjYGBERmUwm36NFRERz9p122W97aq9z0Z6c5zSc5zQ64nmOcK75YO3xu/GffeZyuY/cNu/x8fe//z22bNkSffr0abW+T58+8eKLL261fUNDQ0ydOnWr9TU1NfkercOqmF7oCT4ZnOc0nOd0nGs+SHv+bmzatCkqKio+dJuCf7dLfX19TJkypeVxc3Nz/OMf/4iePXtGSUlJXo+VyWSipqYm1qxZE+Xl5XndN//PeU7DeU7DeU7HuU6jvc5zLpeLTZs2RXV19Udum/f42GOPPaJz586xYcOGVus3bNgQVVVVW21fWloapaWlrdb16NEj32O1Ul5e7hc7Aec5Dec5Dec5Hec6jfY4zx91xeM/8n7DadeuXeOggw6KBQsWtKxrbm6OBQsWRG1tbb4PBwB0MO3yZ5cpU6bExIkT4+CDD44vfOELMX369GhqaoqzzjqrPQ4HAHQg7RIfp59+evztb3+LK664ItavXx+f/exn4+GHH97qJtTUSktL48orr9zqzzzkl/OchvOchvOcjnOdxs5wnktyH+c9MQAAeeK7XQCApMQHAJCU+AAAkhIfAEBSn7j4mDZtWpSUlMTkyZMLPUrRueqqq6KkpKTVMmTIkEKPVZT++te/xte+9rXo2bNndO/ePQ444IBYunRpoccqKnvuuedWv88lJSVRV1dX6NGKypYtW+Lyyy+PgQMHRvfu3WPQoEFx9dVXf6zvB6FtNm3aFJMnT44BAwZE9+7d49BDD40lS5YUZJaCf7x6SkuWLImf//znMWzYsEKPUrSGDh0a8+fPb3ncpcsn6lcsibfffjsOO+ywOProo+Ohhx6KXr16xcsvvxyf+tSnCj1aUVmyZEls2bKl5fGKFSviuOOOi9NOO62AUxWf6667LmbOnBm33XZbDB06NJYuXRpnnXVWVFRUxAUXXFDo8YrKN77xjVixYkX8+te/jurq6rjjjjti1KhR8cILL8SnP/3ppLN8Yl4ZNm/eHBMmTIhbb701rrnmmkKPU7S6dOmyzY/RJ3+uu+66qKmpiVmzZrWsGzhwYAEnKk69evVq9XjatGkxaNCgOPLIIws0UXF68skn46STTooTTzwxIv59xWnu3Lnx9NNPF3iy4vLPf/4z7r777rj//vtj5MiREfHvq9UPPPBAzJw5M/nr4ifmzy51dXVx4oknxqhRowo9SlF7+eWXo7q6Ovbaa6+YMGFCrF69utAjFZ3f//73cfDBB8dpp50WvXv3js997nNx6623Fnqsovbee+/FHXfcEWeffXbev/Dyk+7QQw+NBQsWxEsvvRQREc8++2w88cQTMWbMmAJPVlz+9a9/xZYtW6Jbt26t1nfv3j2eeOKJ5PN8Iq583HnnnfHMM88U7G9bnxQjRoyI2bNnx+DBg2PdunUxderUOOKII2LFihVRVlZW6PGKxl/+8peYOXNmTJkyJb7//e/HkiVL4oILLoiuXbvGxIkTCz1eUbrvvvti48aNceaZZxZ6lKJz6aWXRiaTiSFDhkTnzp1jy5Ytce2118aECRMKPVpRKSsri9ra2rj66qtj3333jT59+sTcuXNj0aJFsffee6cfKFfkVq9enevdu3fu2WefbVl35JFH5r773e8WbqhPiLfffjtXXl6e+8UvflHoUYrKLrvskqutrW21btKkSblDDjmkQBMVv+OPPz73pS99qdBjFKW5c+fm+vXrl5s7d27uueeey91+++25ysrK3OzZsws9WtFZtWpVbuTIkbmIyHXu3Dk3fPjw3IQJE3JDhgxJPkvRX/lYtmxZvPnmm/H5z3++Zd2WLVvi8ccfj5/97GeRzWajc+fOBZywePXo0SP22WefWLVqVaFHKSp9+/aN/fbbr9W6fffdN+6+++4CTVTcXn/99Zg/f37cc889hR6lKF188cVx6aWXxhlnnBEREQcccEC8/vrr0dDQ4Epeng0aNCgWLlwYTU1Nkclkom/fvnH66afHXnvtlXyWor/n49hjj43nn38+li9f3rIcfPDBMWHChFi+fLnwaEebN2+OV155Jfr27VvoUYrKYYcdFitXrmy17qWXXooBAwYUaKLiNmvWrOjdu3fLDZHk1zvvvBOdOrV+KercuXM0NzcXaKLit9tuu0Xfvn3j7bffjnnz5sVJJ52UfIaiv/JRVlYW+++/f6t1u+22W/Ts2XOr9eyYiy66KMaOHRsDBgyItWvXxpVXXhmdO3eO8ePHF3q0onLhhRfGoYceGj/84Q/jK1/5Sjz99NNxyy23xC233FLo0YpOc3NzzJo1KyZOnOht4+1k7Nixce2110b//v1j6NCh8ac//SluuOGGOPvssws9WtGZN29e5HK5GDx4cKxatSouvvjiGDJkSJx11lnJZ/F/E3nzxhtvxPjx4+Ott96KXr16xeGHHx6LFy/e6i2L7Jjhw4fHvffeG/X19fGDH/wgBg4cGNOnT3eDXjuYP39+rF692gthO/rpT38al19+eXznO9+JN998M6qrq+Nb3/pWXHHFFYUereg0NjZGfX19vPHGG1FZWRnjxo2La6+9NnbZZZfks5Tkcj5GDgBIp+jv+QAAdi7iAwBISnwAAEmJDwAgKfEBACQlPgCApMQHAJCU+AAAkhIfAEBS4gMASEp8AABJiQ8AIKn/A8HkhG4jEjgMAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "################################## Plot Histograms (Synthetic Data)\n",
    "N=50\n",
    "n=50\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=9/10# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "plt.hist(y_matrix, bins=m)\n",
    "plt.savefig('hist_k_10_2_0_9.pdf')  \n",
    "plt.show()\n",
    "\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "gamma=1/2\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "plt.hist(y_matrix, bins=m)\n",
    "plt.savefig('hist_k_10_2_0_5.pdf')  \n",
    "plt.show()\n",
    "\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "gamma=1/3\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix = threshold_index(X,Y,Y_sort_index,tau,m,start)\n",
    "plt.hist(y_matrix, bins=m)\n",
    "plt.savefig('hist_k_10_2_0_333.pdf')  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "############################################################ Estim plot (Synthetic Data)\n",
    "\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 3/2 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "start=4\n",
    "l=2 # grid parameter\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "y_matrix2 = threshold(X,Y,Y_sort_index,tau,100,0)\n",
    "y_matrix3 = threshold(X,Y,Y_sort_index,tau,100,4)\n",
    "y_matrix4 = threshold(X,Y,Y_sort_index,tau,100,9)\n",
    "\n",
    "E2 = fepls(X,Y,y_matrix2,tau)\n",
    "E3 = fepls(X,Y,y_matrix3,tau)\n",
    "E4 = fepls(X,Y,y_matrix4,tau)\n",
    "\n",
    "#############################################################################\n",
    "print(check_cond_no_q(gamma,c,tau))\n",
    "##################################################################################################\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "#max_values = np.max(E, axis=0) # shape (d,)\n",
    "#min_values = np.min(E, axis=0) # shape (d,)\n",
    "max_values2 = np.nanquantile(E2, 0.95, axis=0) # shape (d,)\n",
    "min_values2 = np.nanquantile(E2, 0.05, axis=0) # shape (d,)\n",
    "mean_values2 = np.nanmean(E2, axis=0) # shape (d,)\n",
    "median_values2 = np.nanmedian(E2, axis=0) # shape (d,)\n",
    "\n",
    "# Create x values (assuming x values are just indices in this case)\n",
    "x_values = np.arange(d)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [0,1]\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "ax.set_xticklabels([0,0 , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 ])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "ax.fill_between(x_values, min_values2, max_values2, color='skyblue', alpha=0.4)\n",
    "ax.plot(x_values, mean_values2)\n",
    "ax.plot(x_values, beta_func(d))\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "#plt.legend()\n",
    "# Show the plot\n",
    "plt.savefig('beta_estim_plot_conc100_0_1_5_0_333.pdf')  \n",
    "plt.show()\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "#max_values = np.max(E, axis=0) # shape (d,)\n",
    "#min_values = np.min(E, axis=0) # shape (d,)\n",
    "max_values3 = np.nanquantile(E3, 0.95, axis=0) # shape (d,)\n",
    "min_values3 = np.nanquantile(E3, 0.05, axis=0) # shape (d,)\n",
    "mean_values3 = np.nanmean(E3, axis=0) # shape (d,)\n",
    "median_values3 = np.nanmedian(E3, axis=0) # shape (d,)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [0,1]\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "ax.set_xticklabels([0,0 , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 ])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "ax.fill_between(x_values, min_values3, max_values3, color='skyblue', alpha=0.4)\n",
    "ax.plot(x_values, mean_values3)\n",
    "ax.plot(x_values, beta_func(d))\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "#plt.legend()\n",
    "# Show the plot\n",
    "plt.savefig('beta_estim_plot_conc100_4_1_5_0_333.pdf')  \n",
    "plt.show()\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "#max_values = np.max(E4, axis=0) # shape (d,)\n",
    "#min_values = np.min(E4, axis=0) # shape (d,)\n",
    "max_values4 = np.nanquantile(E4, 0.95, axis=0) # shape (d,)\n",
    "min_values4 = np.nanquantile(E4, 0.05, axis=0) # shape (d,)\n",
    "mean_values4 = np.nanmean(E4, axis=0) # shape (d,)\n",
    "median_values4 = np.nanmedian(E4, axis=0) # shape (d,)\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [0,1]\n",
    "ax.xaxis.set_major_locator(plt.MaxNLocator(12))\n",
    "ax.set_xticklabels([0,0 , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1 ])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "ax.fill_between(x_values, min_values4, max_values4, color='skyblue', alpha=0.4)\n",
    "ax.plot(x_values, mean_values4)\n",
    "ax.plot(x_values, beta_func(d))\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "#plt.legend()\n",
    "# Show the plot\n",
    "plt.savefig('beta_estim_plot_conc100_9_1_5_0_333.pdf')  \n",
    "plt.show()\n",
    "\n",
    "print(\"Time cost\",time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### Hyperparameters and Sample\n",
    "\n",
    "N=50\n",
    "n=50\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 2 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Y_sim=Y\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "\n",
    "\n",
    "#################################################### Correlation (concomittant) plot (Synthetic data)\n",
    "\n",
    "m=int(n/2) # 1\\le m \\le n\n",
    "tic=time.time()\n",
    "A=concomittant_corr(X,Y,Y_sort_index,-1,m)[:,1:]\n",
    "A2=concomittant_corr(X,Y,Y_sort_index,-2,m)[:,1:]\n",
    "A3=concomittant_corr(X,Y,Y_sort_index,-3,m)[:,1:]\n",
    "print(\"Time cost\",time.time()-tic)\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "\n",
    "mean_values_A = np.nanmean(A, axis=0) # shape (int(n/l),)\n",
    "#median_values_A = np.nanmedian(A, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A2 = np.nanmean(A2, axis=0) # shape (int(n/l),)\n",
    "#median_values_A2 = np.nanmedian(A2, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A3 = np.nanmean(A3, axis=0) # shape (int(n/l),)\n",
    "#median_values_A3 = np.nanmedian(A3, axis=0) # shape (int(n/l),)\n",
    "\n",
    "# Create x values (assuming x values are just indices in this case)\n",
    "x_values_A = np.arange(m-1)#np.arange(int(n/l))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Set x-axis tick labels to discretized interval [1,250]\n",
    "#ax.xaxis.set_major_locator(plt.MaxNLocator(27))\n",
    "#ax.set_xticklabels([1, 1, 10 , 20, 30,  40, 50, 60, 70, 80, 90, 100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250])\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "#ax.fill_between(x_values_A, min_values_A, max_values_A, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A, label='tau = -1')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A2, max_values_A2, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A2, label='tau = -2')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A3, max_values_A3, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A3, label='tau = -3')\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "plt.legend()\n",
    "plt.savefig('beta_estim_corr_2_0_333.pdf')\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### Hyperparameters and Sample\n",
    "\n",
    "N=500\n",
    "n=500\n",
    "d=101\n",
    "s_Y=1 # scale parameter of Pareto/Lomax distribution\n",
    "c= 1 # c is \\kappa the tail index of g\n",
    "tau=-2 # tail index of \\vfi\n",
    "#nu = 1 #  tail index of \\psi such that 2\\gamma \\nu_j < 1 for all 1\\le j \\le J\n",
    "snr=10 # signal-to-noise ratio\n",
    "H=1/3 # Hurst parameter of fBm noise\n",
    "gamma=1/3# 1/3 or 1/2 or 9/10\n",
    "rho=-1/2\n",
    "mu = 200 # noise mean\n",
    "l=2 # grid parameter\n",
    "start = 4\n",
    "\n",
    "tic=time.time()\n",
    "\n",
    "#Y=Pareto_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "#Y=Lomax_quantile_function(npr.uniform(0,1,size=(N,n)),theta,s_Y)\n",
    "Y=Burr_quantile_function(npr.uniform(0,1,size=(N,n)),gamma,rho)\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "Y_sim=Y\n",
    "\n",
    "Z=npr.normal(0,1,size=(N,n,d - 1)) # latent variables for fBm sampling\n",
    "aux=np.multiply.outer(Y**c,beta_func(d)) # g(Y)\\beta\n",
    "eps=coeurjolly_cholesky_fbm_var(Y,Z,H,c,snr,mu) \n",
    "X=aux+eps\n",
    "Y_sort_index = np.argsort(Y,axis=1)\n",
    "m=int(n/5)\n",
    "\n",
    "####################################################### hatbeta_dot_beta (Synthetic Data)\n",
    "\n",
    "l=2 # grid parameter\n",
    "A=hatbeta_dot_beta(X,Y,-1,l)\n",
    "A2=hatbeta_dot_beta(X,Y,-2,l)\n",
    "A3=hatbeta_dot_beta(X,Y,-3,l)\n",
    "\n",
    "print(\"Time cost\",time.time()-tic)\n",
    "\n",
    "# Calculate the maximum and minimum values for each position\n",
    "mean_values_A = np.nanmean(A, axis=0) # shape (int(n/l),)\n",
    "#median_values_A = np.nanmedian(A, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A2 = np.nanmean(A2, axis=0) # shape (int(n/l),)\n",
    "#median_values_A2 = np.nanmedian(A2, axis=0) # shape (int(n/l),)\n",
    "\n",
    "mean_values_A3 = np.nanmean(A3, axis=0) # shape (int(n/l),)\n",
    "#median_values_A3 = np.nanmedian(A3, axis=0) # shape (int(n/l),)\n",
    "\n",
    "# Create x values (assuming x values are just indices in this case)\n",
    "x_values_A = np.arange(int(n/l))\n",
    "\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Plot the fill between the max and min values\n",
    "#ax.fill_between(x_values_A, min_values_A, max_values_A, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A, label='tau = -2')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A2, max_values_A2, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A2, label='tau = -3')\n",
    "\n",
    "#ax.fill_between(x_values_A, min_values_A3, max_values_A3, color='skyblue', alpha=0.4, label='Confidence Area')\n",
    "ax.plot(x_values_A, mean_values_A3, label='tau = -4')\n",
    "\n",
    "# Add labels and legend\n",
    "#ax.xlabel('Index')\n",
    "#ax.ylabel('Values')\n",
    "#ax.title('FEPLS Estimation of beta - Confidence intervals')\n",
    "plt.legend()\n",
    "#plt.savefig('beta_estim_exceedance_1_5_0_9.pdf')\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
